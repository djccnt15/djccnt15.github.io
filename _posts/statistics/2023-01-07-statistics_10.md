---
published: true
layout: post
title: '[ê¸°ì´ˆí†µê³„í•™] 10. ë‹¤ì–‘í•œ ì´ì‚°í™•ë¥ ë¶„í¬'
description: >
    ë² ë¥´ëˆ„ì´ ë¶„í¬, ì´í•­ë¶„í¬, ì´ˆê¸°í•˜ë¶„í¬
categories: [Statistics]
tags: [statistics]
image:
    path: /assets/img/posts/thumbnail_statistics_10.png
related_posts:
    - _posts/statistics/2023-01-01-statistics_09.md
---
{% include series_statistics.html %}
* toc
{:toc}

## 1. ë² ë¥´ëˆ„ì´ ë¶„í¬

ë‹¤ìŒì˜ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì‹¤í—˜ì„ **ë² ë¥´ëˆ„ì´ ì‹œí–‰(Bernoulli trial)**ì´ë¼ í•œë‹¤.  

- ê° ì‹¤í—˜ì—ì„œ ë°œìƒ ê°€ëŠ¥í•œ ê²°ê³¼ê°€ ë‹¨ ë‘ ê°€ì§€
- ê° ì‹¤í—˜ì€ ë…ë¦½ì ìœ¼ë¡œ ìˆ˜í–‰
- ëª¨ë“  ì‹¤í—˜ì—ì„œ ê²°ê³¼ì˜ í™•ë¥ ì€ í•­ìƒ ë™ì¼

ğŸ’¡ ëª¨ì§‘ë‹¨ì´ ì¶©ë¶„íˆ í¬ê³  í‘œë³¸í¬ê¸°ê°€ ìƒëŒ€ì ìœ¼ë¡œ í¬ì§€ ì•Šì€ ê²½ìš° ë¹„ë³µì›ì¶”ì¶œë„ ë² ë¥´ëˆ„ì´ ì‹¤í—˜ì„ ê·¼ì‚¬ëª¨í˜•ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•˜ë‹¤.  
{:.note}

ëª¨ìˆ˜(parameter)ì¸ ì„±ê³µ í™•ë¥ ì´ $$p$$ì¸ ë² ë¥´ëˆ„ì´ ì‹œí–‰ì˜ í™•ë¥ ë³€ìˆ˜ì˜ ë¶„í¬ë¥¼ **ë² ë¥´ëˆ„ì´ ë¶„í¬(Bernoulli distribution)**ë¼ í•˜ê³ , ì•„ë˜ì™€ ê°™ì´ í‘œê¸°í•œë‹¤.  

$$X \sim B(p)$$

ë² ë¥´ëˆ„ì´ ë¶„í¬ì˜ í™•ë¥ ì§ˆëŸ‰í•¨ìˆ˜ì˜ ì¼ë°˜ì‹ì€ ì•„ë˜ì™€ ê°™ë‹¤.  

$$f(x) = P(X = x) = p^{x}(1 - p)^{1 - x}, \quad x = 0, \ 1$$

ë² ë¥´ëˆ„ì´ ë¶„í¬ì˜ í™•ë¥ ì§ˆëŸ‰í•¨ìˆ˜ë¥¼ Pythonìœ¼ë¡œ êµ¬í˜„í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.  

```python
def bernoulli_d(x: int, p: float, n: int = 1) -> float:
    """
    returns probability of bernoulli distribution
    x: case
    p: probability
    """

    res = (p ** x) * ((1 - p) ** (n - x))
    return res
```

ë² ë¥´ëˆ„ì´ ë¶„í¬ì˜ ê¸°ëŒ€ê°’ê³¼ ë¶„ì‚°ì€ ì•„ë˜ì™€ ê°™ë‹¤.  

$$\begin{align*}
& E(X) = 0 \times (1 - p) + 1 \times p = p \\
\\
& E(X^{2}) = 0^{2} \times (1 - p) + 1^{2} \times p = p \\
\\
& Var(X) = p - p^{2} = p(1 - p) \\
\\
& SD(X) = \sqrt{p(1 - p)}
\end{align*}$$

## 2. ì´í•­ë¶„í¬

ì„±ê³µ í™•ë¥ ì´ $$p$$ì¸ ë² ë¥´ëˆ„ì´ ì‹¤í—˜ì„ $$n$$ë²ˆ ë°˜ë³µí–ˆì„ ë•Œ, ì„±ê³µ íšŸìˆ˜ $$X$$ì˜ ë¶„í¬ë¥¼ **ì´í•­ë¶„í¬(binomial distribution)**ë¼ í•œë‹¤.  

$$X_{i} \sim B(p)$$ë¼ê³  í•  ë•Œ, ì„±ê³µ íšŸìˆ˜ $$X$$ëŠ” $$n$$ê°œì˜ ë² ë¥´ëˆ„ì´ í™•ë¥ ë³€ìˆ˜ì˜ í•©ìœ¼ë¡œ í‘œì‹œí•œë‹¤.  

$$X = X_{1} + X_{2} + \cdots + X_{n}$$

ë”°ë¼ì„œ ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´í•­ë¶„í¬ì˜ ê¸°ëŒ€ê°’ê³¼ ë¶„ì‚°ì„ ìœ ë„í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.  

$$\begin{align*}
E(X_{i}) = p \ & \to \ E(X) = np \\
\\
Var(X_{i}) = p(1 - p) \ & \to \ Var(X) = np(1 - p) \\
\\
SD(X_{i}) = \sqrt{p(1 - p)} \ & \to \ SD(X) = \sqrt{np(1 - p)}
\end{align*}$$

ì‹œí–‰íšŸìˆ˜ë¥¼ $$n$$, ì„±ê³µí™•ë¥  $$p$$ì¸ ì´í•­ë¶„í¬ë¥¼ ì•„ë˜ì™€ ê°™ì´ í‘œê¸°í•œë‹¤.  

$$X \sim B(n, p)$$

ì´í•­ë¶„í¬ì˜ í™•ë¥ ì§ˆëŸ‰í•¨ìˆ˜ì˜ ì¼ë°˜ì‹ì€ ì•„ë˜ì™€ ê°™ë‹¤.  

$$f(x) = \binom{n}{x}p^{x}(1 - p)^{n - x}, \quad x = 0, 1, \cdots, n$$

ì´í•­ë¶„í¬ì˜ í™•ë¥ ì§ˆëŸ‰ í•¨ìˆ˜ë¥¼ Pythonìœ¼ë¡œ êµ¬í˜„í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.  

```python
def binom_d(x: int, n: int, p: float) -> float:
    """
    returns probability of binom distribution
    x: case
    n: number of trial
    p: probability
    """

    res = combination(n, x) * bernoulli_d(x=x, n=n, p=p)
    return res


def binom_c(x: int, n: int, p: float) -> float:
    """
    returns cumulative probability of binom distribution
    x: case
    n: number of trial
    p: probability
    """

    res = sum(binom_d(i, n, p) for i in range(x + 1))
    return res
```

$$X \sim B(m, p), Y \sim B(n, p)$$ì´ê³  $$X, Y$$ê°€ ë…ë¦½ì¸ ê²½ìš° ì´í•­ë¶„í¬ì˜ ê²°í•©ì€ ì•„ë˜ì™€ ê°™ë‹¤.  

$$X + Y \sim B(m + n, p)$$

ì•„ë˜ì™€ ê°™ì´ NumPyë¥¼ ì‚¬ìš©í•˜ë©´ ì´í•­ë¶„í¬í•˜ëŠ” í‘œë³¸ì„ ì‰½ê²Œ ë§Œë“¤ ìˆ˜ ìˆë‹¤.  

```python
import numpy as np

n = 10      # number of trials
p = 0.5     # probability of each trial
size = 100  # size of data
data = np.random.default_rng(seed=0).binomial(n=n, p=p, size=size)
```

## 3. ì´ˆê¸°í•˜ë¶„í¬

ê° ì‹¤í—˜ì—ì„œ ë°œìƒ ê°€ëŠ¥í•œ ê²°ê³¼ê°€ ë‹¨ ë‘ ê°€ì§€ì´ê³ , í¬ê¸°ê°€ $$N$$ì¸ ëª¨ì§‘ë‹¨(ìœ í•œëª¨ì§‘ë‹¨)ì´ ê°ê° $$M$$ê³¼ $$N - M$$ í¬ê¸°ì˜ ë¶€ëª¨ì§‘ë‹¨ $$A, B$$ë¡œ ë‚˜ë‰˜ì–´ì§„ ê²½ìš°ì—ì„œ $$n$$ê°œì˜ í‘œë³¸ì„ ë¬´ì‘ìœ„ë¡œ ë¹„ë³µì›ì¶”ì¶œí•  ë•Œ, ë¶€ëª¨ì§‘ë‹¨ $$A$$ì—ì„œ ì¶”ì¶œëœ í‘œë³¸ ìˆ˜ì˜ ë¶„í¬ë¥¼ **ì´ˆê¸°í•˜ë¶„í¬(hypergeometric distribution)**ë¼ í•œë‹¤.  

ì´ˆê¸°í•˜ë¶„í¬ì˜ í™•ë¥ ì§ˆëŸ‰í•¨ìˆ˜ì˜ ì¼ë°˜ì‹ì€ ì•„ë˜ì™€ ê°™ë‹¤.  

$$f(x) = \frac{\binom{M}{x}\binom{N - M}{n - x}}{\binom{N}{n}}, \quad x = max(0, n - N + M), \cdots, min(n, M)$$

ì´ˆê¸°í•˜ë¶„í¬ì˜ í™•ë¥ ì§ˆëŸ‰í•¨ìˆ˜ë¥¼ Pythonìœ¼ë¡œ êµ¬í˜„í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.  

```python
def hyper_d(x: int, M: int, n: int, N: int) -> float:
    """
    returns probability of hypergeometric distribution
    x: case
    M: size of subpopulation
    n: size of sample
    N: size of population
    """

    res = combination(M, x) * combination(N - M, n - x) / combination(N, n)
    return res


def hyper_c(x: int, M: int, n: int, N: int) -> float:
    """
    returns cumulative probability of hypergeometric distribution
    x: case
    M: size of subpopulation
    n: size of sample
    N: size of population
    """

    res = sum(combination(M, x) * combination(N - M, n - x) / combination(N, n) for x in range(x + 1))
    return res
```

$$N$$ì´ í¬ê³  $$N$$ì— ë¹„í•´ $$n$$ì´ ìƒëŒ€ì ìœ¼ë¡œ ë§¤ìš° ì‘ì€ ê²½ìš°($$n \ll N$$) ë¹„ë³µì›ì˜ íš¨ê³¼ê°€ ì ê¸° ë•Œë¬¸ì— ë² ë¥´ëˆ„ì´ ì‹¤í—˜ìœ¼ë¡œ ê·¼ì‚¬í•˜ë©°, ë”°ë¼ì„œ ì´ˆê¸°í•˜ë¶„í¬ ì—­ì‹œ $$p = M/N$$ì¸ ì´í•­ë¶„í¬ë¡œ ê·¼ì‚¬í•œë‹¤.  

ì´ˆê¸°í•˜ë¶„í¬ì˜ ê¸°ëŒ€ê°’ê³¼ ë¶„ì‚°ì€ ì•„ë˜ì™€ ê°™ë‹¤.  

$$\begin{align*}
E(X) & = n \frac{M}{N} = np \\
\\
Var(X) & = np(1 - p) - n(n - 1)\frac{p(1 - p)}{N - 1} \\
& = np(1 - p)\frac{N - n}{N - 1} = n\frac{M}{N} \left( 1 - \frac{M}{N} \right) \leq np(1 - p)
\end{align*}$$

<details><summary>ì´ˆê¸°í•˜ë¶„í¬ ê¸°ëŒ€ê°’ê³¼ ë¶„ì‚°ì˜ ìœ ë„</summary><div markdown="1">

$$E(X_{i}) = \frac{M}{N} = p \ \to \ E(X) = n \frac{M}{N} = np$$

$$\begin{align*}
E(X_{i}) & = \frac{M}{N} = p, \quad E(X_{i}^{2}) = \frac{M}{N} = p \\
\\
\therefore Var(X_{i}) & = p - p^{2} = p(1 - p) = \frac{M}{N}\frac{N - M}{N} \\
\\
\therefore Var(X) & = \sum_{i}Var(X_{i}) + 2\sum_{i < j}Cov(X_{i}, X_{j}) \\
\\
Cov(X_{i}, X_{j}) & = E(X_{i}X_{j}) - E(X_{i})E(X_{j}) \\
\\
E(X_{i}X_{j}) & = P(X_{i} = 1, X_{j} = 1) \quad \because X_{i} = 0 \ \to \ E(X_{i}X_{j}) = 0 \\
& = P(X_{i} = 1)P({X_{j} = 1 \vert X_{i} = 1}) = \frac{M}{N}\frac{M - 1}{N - 1} \\
\\
\therefore Cov(X_{i}, X_{j}) & = \frac{M}{N}\frac{M - 1}{N - 1} - \left( \frac{M}{N} \right)^{2} \\
& = -\frac{M}{N}\frac{N - M}{N(N - 1)} = -\frac{p(1 - p)}{N - 1} \leq 0 \\
\\
\therefore Var(X) & = np(1 - p) - n(n - 1)\frac{p(1 - p)}{N - 1} \\
& = np(1 - p)\frac{N - n}{N - 1}
\end{align*}$$

</div></details><br>

ì´ ë•Œ ìœ„ ì‹ì—ì„œ $$\frac{N - n}{N - 1}$$ì„ ìœ í•œëª¨ì§‘ë‹¨ ìˆ˜ì •ê³„ìˆ˜ë¼ í•œë‹¤.  

ìœ í•œëª¨ì§‘ë‹¨ìœ¼ë¡œë¶€í„° ë¹„ë³µì› ì¶”ì¶œì„ í•˜ë©´ì„œ ë¶„ì‚°ì´ ì‘ì•„ì§„ë‹¤ëŠ” ê²ƒì€ í¼ì ¸ìˆëŠ” ì •ë„ê°€ ì‘ì•„ì ¸ ë°ì´í„°ì˜ ë³€ë™ì„±ì´ ì ì–´ì§„ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ëª¨ìˆ˜ë¥¼ ì¶”ì •í–ˆì„ ë•Œ ë” ì•ˆì •ì ì¸ í˜•íƒœë¥¼ ê°–ëŠ”ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.  

ì•„ë˜ì™€ ê°™ì´ NumPyë¥¼ ì‚¬ìš©í•˜ë©´ ì´ˆê¸°í•˜ë¶„í¬í•˜ëŠ” í‘œë³¸ì„ ì‰½ê²Œ ë§Œë“¤ ìˆ˜ ìˆë‹¤.  

```python
import numpy as np

data = np.random.default_rng(seed=0).hypergeometric(ngood=20, nbad=20, nsample=10, size=100)
```

---
## Reference
- [êµ¬í˜„í•œ í•¨ìˆ˜ git repository](https://github.com/djccnt15/mathematics)