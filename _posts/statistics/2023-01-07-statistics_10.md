---
published: true
layout: post
title: '[기초통계학] 10. 다양한 이산확률분포'
description: >
    베르누이 분포, 이항 분포, 초기하 분포, 포아송 분포, 기하 분포
categories: [Statistics]
tags: [statistics]
image:
    path: /assets/img/posts/thumbnail_statistics_10.png
related_posts:
    - _posts/statistics/2023-01-01-statistics_09.md
---
{% include series_statistics.html %}
* toc
{:toc}

## 1. 베르누이 분포

다음의 조건을 만족하는 실험을 **베르누이 시행(Bernoulli trial)**이라 한다.  

- 각 실험에서 발생 가능한 결과가 단 두 가지
- 각 실험은 독립적으로 수행
- 모든 실험에서 결과의 확률은 항상 동일

💡 모집단이 충분히 크고 표본크기가 상대적으로 크지 않은 경우 비복원추출도 베르누이 실험을 근사모형으로 사용 가능하다.  
{:.note}

모수(parameter)인 성공 확률이 $$p$$인 베르누이 시행의 확률변수의 분포를 **베르누이 분포(Bernoulli distribution)**라 하고, 아래와 같이 표기한다.  

$$X \sim B(p)$$

베르누이 분포의 확률질량함수의 일반식은 아래와 같다.  

$$f(x) = P(X = x) = p^{x}(1 - p)^{1 - x}, \quad x = 0, 1$$

베르누이 분포의 확률질량함수를 Python으로 구현하면 아래와 같다.  

```python
def bernoulli_d(x: int, p: float, n: int = 1) -> float:
    """
    returns probability of bernoulli distribution
    x: case
    p: probability
    """

    res = (p ** x) * ((1 - p) ** (n - x))
    return res
```

베르누이 분포의 기대값과 분산은 아래와 같다.  

$$\begin{align*}
& E(X) = 0 \times (1 - p) + 1 \times p = p \\
\\
& E(X^{2}) = 0^{2} \times (1 - p) + 1^{2} \times p = p \\
\\
& Var(X) = p - p^{2} = p(1 - p) \\
\\
& SD(X) = \sqrt{p(1 - p)}
\end{align*}$$

## 2. 이항 분포

성공 확률이 $$p$$인 베르누이 실험을 $$n$$번 반복했을 때, 성공 횟수 $$X$$의 분포를 **이항 분포(binomial distribution)**라 한다.  

$$X_{i} \sim B(p)$$라고 할 때, 성공 횟수 $$X$$는 $$n$$개의 베르누이 확률변수의 합으로 표시한다.  

$$X = X_{1} + X_{2} + \cdots + X_{n}$$

따라서 [독립인 결합 분포의 성질](/statistics/statistics_09/#2-공분산과-상관계수)을 바탕으로 이항 분포의 기대값과 분산을 유도하면 아래와 같다.  

$$\begin{align*}
E(X_{i}) = p \ & \to \ E(X) = np \\
\\
Var(X_{i}) = p(1 - p) \ & \to \ Var(X) = np(1 - p) \\
\\
SD(X_{i}) = \sqrt{p(1 - p)} \ & \to \ SD(X) = \sqrt{np(1 - p)}
\end{align*}$$

시행 횟수를 $$n$$, 성공 확률 $$p$$인 이항 분포를 아래와 같이 표기한다.  

$$X \sim B(n, p)$$

이항 분포의 확률질량함수의 일반식은 아래와 같다.  

$$f(x) = \binom{n}{x}p^{x}(1 - p)^{n - x}, \quad x = 0, 1, \cdots, n$$

이항 분포의 확률질량함수를 Python으로 구현하면 아래와 같다.  

```python
def binom_d(x: int, n: int, p: float) -> float:
    """
    returns probability of binom distribution
    x: case
    n: number of trial
    p: probability
    """

    res = combination(n, x) * bernoulli_d(x=x, n=n, p=p)
    return res


def binom_c(x: int, n: int, p: float) -> float:
    """
    returns cumulative probability of binom distribution
    x: case
    n: number of trial
    p: probability
    """

    res = sum(binom_d(i, n, p) for i in range(x + 1))
    return res
```

$$X \sim B(m, p), Y \sim B(n, p)$$이고 $$X, Y$$가 독립인 경우 이항 분포의 결합은 아래와 같다.  

$$X + Y \sim B(m + n, p)$$

아래와 같이 NumPy를 사용하면 이항 분포하는 표본을 쉽게 만들 수 있다.  

```python
import numpy as np

n = 10      # number of trials
p = 0.5     # probability of each trial
size = 100  # size of data
data = np.random.default_rng(seed=0).binomial(n=n, p=p, size=size)
```

## 3. 초기하 분포

각 실험에서 발생 가능한 결과가 단 두 가지이고, 크기가 $$N$$인 모집단(유한모집단)이 각각 $$M$$과 $$N - M$$ 크기의 부모집단 $$A, B$$로 나뉘어진 경우에서 $$n$$개의 표본을 무작위로 비복원추출할 때, 부모집단 $$A$$에서 추출된 표본 수의 분포를 **초기하 분포(hypergeometric distribution)**라 한다.  

초기하 분포의 확률질량함수의 일반식은 아래와 같다.  

$$f(x) = \frac{\binom{M}{x}\binom{N - M}{n - x}}{\binom{N}{n}}, \quad x = max(0, n - N + M), \cdots, min(n, M)$$

초기하 분포의 확률질량함수를 Python으로 구현하면 아래와 같다.  

```python
def hyper_d(x: int, M: int, n: int, N: int) -> float:
    """
    returns probability of hypergeometric distribution
    x: case
    M: size of subpopulation
    n: size of sample
    N: size of population
    """

    res = combination(M, x) * combination(N - M, n - x) / combination(N, n)
    return res


def hyper_c(x: int, M: int, n: int, N: int) -> float:
    """
    returns cumulative probability of hypergeometric distribution
    x: case
    M: size of subpopulation
    n: size of sample
    N: size of population
    """

    res = sum(combination(M, x) * combination(N - M, n - x) / combination(N, n) for x in range(x + 1))
    return res
```

$$N$$이 크고 $$N$$에 비해 $$n$$이 상대적으로 매우 작은 경우($$n \ll N$$) 비복원의 효과가 적기 때문에 베르누이 실험으로 근사하며, 따라서 초기하 분포 역시 $$p = M/N$$인 이항 분포로 근사한다.  

초기하 분포의 기대값과 분산은 아래와 같다.  

$$\begin{align*}
E(X) & = n \frac{M}{N} = np \\
\\
Var(X) & = np(1 - p) - n(n - 1)\frac{p(1 - p)}{N - 1} \\
& = np(1 - p)\frac{N - n}{N - 1} = n\frac{M}{N} \left( 1 - \frac{M}{N} \right) \leq np(1 - p)
\end{align*}$$

<details><summary>초기하 분포 기대값과 분산의 유도</summary><div markdown="1">

$$E(X_{i}) = \frac{M}{N} = p \ \to \ E(X) = n \frac{M}{N} = np$$

$$\begin{align*}
E(X_{i}) & = \frac{M}{N} = p, \quad E(X_{i}^{2}) = \frac{M}{N} = p \\
\\
\therefore Var(X_{i}) & = p - p^{2} = p(1 - p) = \frac{M}{N}\frac{N - M}{N} \\
\\
\therefore Var(X) & = \sum_{i}Var(X_{i}) + 2\sum_{i < j}Cov(X_{i}, X_{j}) \\
\\
Cov(X_{i}, X_{j}) & = E(X_{i}X_{j}) - E(X_{i})E(X_{j}) \\
\\
E(X_{i}X_{j}) & = P(X_{i} = 1, X_{j} = 1) \quad \because X_{i} = 0 \ \to \ E(X_{i}X_{j}) = 0 \\
& = P(X_{i} = 1)P({X_{j} = 1 \vert X_{i} = 1}) = \frac{M}{N}\frac{M - 1}{N - 1} \\
\\
\therefore Cov(X_{i}, X_{j}) & = \frac{M}{N}\frac{M - 1}{N - 1} - \left( \frac{M}{N} \right)^{2} \\
& = -\frac{M}{N}\frac{N - M}{N(N - 1)} = -\frac{p(1 - p)}{N - 1} \leq 0 \\
\\
\therefore Var(X) & = np(1 - p) - n(n - 1)\frac{p(1 - p)}{N - 1} \\
& = np(1 - p)\frac{N - n}{N - 1}
\end{align*}$$

</div></details><br>

이 때 위 식에서 $$\frac{N - n}{N - 1}$$을 유한모집단 수정계수라 한다.  

유한모집단으로부터 비복원추출을 하면서 분산이 작아진다는 것은 퍼져있는 정도가 작아져 데이터의 변동성이 적어진다는 것을 의미하고, 이를 바탕으로 모수를 추정했을 때 더 안정적인 형태를 갖는다는 것을 의미한다.  

아래와 같이 NumPy를 사용하면 초기하 분포하는 표본을 쉽게 만들 수 있다.  

```python
import numpy as np

data = np.random.default_rng(seed=0).hypergeometric(ngood=20, nbad=20, nsample=10, size=100)
```

## 4. 포아송 분포

[이항 분포](#2-이항 분포)에서 $$n$$이 매우 커지면 계산에 어려움이 생기는데, 이를 해결하기 위해 포아송 분포를 사용한다.  

확률변수 $$X$$가 이항 분포 $$B(n, p)$$를 따를 때 $$p$$가 매우 작으면 큰 $$x$$에 대한 확률은 무시할 정도로 작아지는데, 이 경우의 확률분포를 **포아송 분포(Poisson distribution)**라 하며 아래와 같이 표기한다.  

$$X \sim \text{Pois}(\lambda)$$

즉, 발생 가능성이 희박한 사건이 임의의 구간에서 평균적으로 $$\lambda$$번 발생하는 상황에서, 구간을 나누었을 때 각 구간의 발생 빈도는 서로 독립(independent increment)이고 구간의 위치와 관계없이 동일 길이의 구간에서의 평균발생 빈도는 동일(stationary increment)하면 해당 분포는 포아송 분포를 따른다고 할 수 있다.  

포아송 분포의 확률질량함수는 아래와 같다.  

$$f(x) = \binom{n}{x}p^{x}(1 - p)^{n - x} \simeq \frac{e^{-\lambda}\lambda^{x}}{x!}, \quad \lambda = np = E(X)$$

<details><summary>포아송 분포의 확률질량함수 유도</summary><div markdown="1"><br>

이항 분포하는 확률변수 $$X$$의 확률질량함수를 $$\lambda$$를 이용해서 정리하면 아래와 같다.  

$$\begin{gathered}
E(X) = \lambda = np \ \to \ p = \frac{\lambda}{n} \\
\\
\Rightarrow f(x) = \binom{n}{x}p^{x}(1 - p)^{n - x} = \frac{n!}{x!(n - x)!} \left( \frac{\lambda}{n} \right)^{x} \left( 1 - \frac{\lambda}{n} \right)^{n - x}
\end{gathered}$$

위 식에서 $$n$$이 무한대로 발산하면 아래와 같이 정리된다.  

$$\begin{gathered}
\frac{n!}{(n - x)!n^{x}} = \frac{n(n - 1) \cdots (n - x + 1)}{n^{x}} \ \to \ 1 \\
\\
\lim_{n \to \infty} \left( 1 - \frac{\lambda}{n} \right)^{n} = e^{-\lambda}, \quad \because \lim_{n \to \infty} \left( 1 + \frac{x}{n} \right)^{n} = e^{x} \\
\\
\lim_{n \to \infty} \left( 1 - \frac{\lambda}{n} \right)^{-x} = 1 \\
\\
\Rightarrow f(x) = \binom{n}{x}p^{x}(1 - p)^{n - x} \simeq \frac{e^{-\lambda}\lambda^{x}}{x!}
\end{gathered}$$

</div></details><br>

💡 $$p$$가 커질수록 포아송 근사와 이항분포의 오차가 커지는데, 일반적으로 $$\lambda$$ 값이 5보다 작으면 포아송 근사를 사용해도 큰 문제가 없다고 한다.  
{:.note}

포아송 분포의 확률질량함수를 Python으로 구현하면 아래와 같다.  

```python
import math


def pois_d(x: int, l: float) -> float:
    """
    returns probability of poisson distribution
    x: case
    l: lambda, expectation of random variable
    """

    res = (math.e ** -l) * (l ** x) / factorial(x)
    return res


def pois_c(x: int, l: float) -> float:
    """
    returns cumulative probability of poisson distribution
    x: case
    l: lambda, expectation of random variable
    """

    res = sum(pois_d(i, l) for i in range(x + 1))
    return res
```

$$X \sim \text{Pois}(\lambda_{1}), Y \sim \text{Pois}(\lambda_{2})$$이고, $$X, Y$$가 독립인 경우 포아송 분포의 결합은 아래와 같다.  

$$X + Y \sim \text{Pois}(\lambda_{1} + \lambda_{2})$$

포아송 분포의 기대값과 분산은 아래와 같다.  

$$\begin{align*}
E(X) & = \lambda \\
\\
Var(X) & = \lambda
\end{align*}$$

<details><summary>포아송 분포 기대값과 분산의 유도</summary><div markdown="1">

$$\begin{align*}
E(X) & = \sum_{x=0}^{\infty}x\frac{e^{-\lambda}\lambda^{x}}{x!} = \sum_{x=1}^{\infty}x\frac{e^{-\lambda}\lambda^{x}}{x!} \\
\\
& = \lambda\sum_{x=1}^{\infty}\frac{e^{-\lambda}\lambda^{x - 1}}{(x - 1)!} \\
\\
y = x - 1 & \ \to \ \lambda\sum_{x=1}^{\infty}\frac{e^{-\lambda}\lambda^{x - 1}}{(x - 1)!} = \lambda\sum_{y=0}^{\infty}\frac{e^{-\lambda}\lambda^{y}}{y!} = \lambda
\end{align*}$$

$$\begin{align*}
Var(X) & = E(X^{2}) - E(X)^{2} \\
\\
& = E(X(X - 1)) + E(X) - E(X)^{2} \\
\\
& = \lambda^{2} + \lambda - \lambda^{2} = \lambda \\
\\
\because E(X(X - 1)) & = E(X^{2}) - E(X) \\
\\
& = \sum_{x=0}^{\infty}x(x - 1)\frac{e^{-\lambda}\lambda^{x}}{x!} = \lambda^{2}\sum_{x=2}^{\infty}\frac{e^{-\lambda}\lambda^{x - 2}}{(x - 2)!} \\
\\
y = x - 2 & \ \to \ \lambda^{2}\sum_{y=0}^{\infty}\frac{e^{-\lambda}\lambda^{y}}{y!} = \lambda^{2}
\end{align*}$$

</div></details><br>

💡 따라서 모집단이 포아송 분포를 따른다면, 기대값과 분산이 비슷한 값을 가진다고 예상할 수 있으며,  
❗ 평균에 비해 표본분산이 매우 크다면($$\overline{x} \ll s^{2}$$) 데이터가 포아송 분포를 따르지 않을 것이라고 예상할 수 있다.  
{:.note}

아래와 같이 NumPy를 사용하면 포아송 분포하는 표본을 쉽게 만들 수 있다.  

```python
import numpy as np

data = np.random.default_rng().poisson(lam=5, size=1000)
```

## 5. 기하 분포

성공 확률이 $$p$$인 [베르누이 시행](#1-베르누이-분포)을 성공할 때까지 시행하는 경우 실패(시행) 횟수의 분포를 **기하 분포(geometric distribution)**라 하고, 아래와 같이 표기한다.  

$$X \sim \text{Geo}(p)$$

기하 분포의 확률질량함수는 아래와 같다.  

$$f(x) = (1 - p)^{x}p, \quad x = 0, 1, 2, \cdots$$

위와 같이 1항이 $$p$$이고 공비가 $$1 - p$$인 등비급수 형태를 갖고 있기 때문에 $$x$$번째 실험 이전에 성공할 확률을 의미하는 기하 분포의 누적분포함수는 등비급수의 합을 기반으로 아래와 같이 유도할 수 있다.  

$$\begin{align*}
P(X \leq x) & = \sum_{k=0}^{x}p(1 - p)^{k} = \frac{p - p(1 - p)^{x + 1}}{1 - (1 - p)} = 1 - (1 - p)^{x + 1} \\
\\
P(X \geq x) & = 1 - P(X \leq x - 1) = (1 - p)^{x}
\end{align*}$$

기하 분포의 확률질량함수를 Python으로 구현하면 아래와 같다.  

```python
def geom_d(x: int, p: float) -> float:
    """
    returns probability of geometric distribution
    x: number of failures
    p: probability
    """

    res = ((1 - p) ** x) * p
    return res


def geom_c(x: int, p: float) -> float:
    """
    returns cumulative probability of geometric distribution
    x: number of failures
    p: probability
    """

    res = 1 - ((1 - p) ** (x + 1))
    return res
```

기하 분포의 확률질량함수를 시행 횟수에 대한 식으로 변환하면, 시행 횟수 $$Y$$는 실패 횟수 $$X + 1$$과 동일하기 때문에 아래와 같이 변형할 수 있다.  

$$Y = X + 1 \ \to \ f_{Y}(y) = (1 - p)^{y - 1}p, \quad y = 1, 2, \cdots$$

따라서 $$x$$번째 실험 이전에 성공할 확률은 아래와 같이 표현할 수 있다.  

$$P(Y \leq x) = P(X \leq x - 1)$$

이를 바탕으로 시행 횟수에 대한 누적분포함수는 아래와 같이 표현할 수 있다.  

$$\begin{align*}
P(Y \leq y) & = P(X + 1 \leq y) = P(X \leq y - 1) = 1 - (1 - p)^{y} \\
\\
P(Y > y) & = 1 - P(Y \leq y) = (1 - p)^{y}
\end{align*}$$

기하 분포의 기대값은 무한등비급수의 합을 기반으로 아래와 같이 유도할 수 있다.  

$$\begin{align*}
E(X) & = \sum_{x=0}^{\infty}xp(1 - p)^{x} = \frac{p(1 - p)}{p^{2}} = \frac{1 - p}{p} \\
\\
E(Y) & = E(X + 1) = \frac{1}{p}
\end{align*}$$

---
## Reference
- [구현한 함수 git repository](https://github.com/djccnt15/mathematics)