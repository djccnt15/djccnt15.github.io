---
published: true
layout: post
title: '[ê¸°ì´ˆí†µê³„í•™] 03. ì¼ë³€ëŸ‰ ìë£Œ'
description: >
    ìˆ˜ì¹˜í˜• ì¼ë³€ëŸ‰ ìë£Œì˜ ì¤‘ì‹¬ê²½í–¥ì¹˜ì™€ ì‚°í¬
categories: [Statistics]
tags: [statistics]
image:
    path: /assets/img/posts/thumbnail_statistics_03.png
related_posts:
    - _posts/statistics/2022-12-17-statistics_02.md
    - _posts/statistics/2022-12-23-statistics_04.md
---
{% include series_statistics.html %}
* toc
{:toc}

## 0. ê¸°ìˆ í†µê³„

ìˆ˜ì§‘ëœ ìë£Œë¥¼ ì •ë¦¬í•˜ì—¬ ìš”ì•½ëœ ê°’ ë° ì‹œê°í™”ë¥¼ í†µí•´ í‘œí˜„í•˜ëŠ” ê²ƒì„ **ê¸°ìˆ í†µê³„(descriptive statistics)**ë¼ í•œë‹¤. ì´ ë•Œ ì¤‘ì‹¬ê²½í–¥ì¹˜(ëŒ€í‘œê°’), ì‚°í¬, ë¶„í¬ì˜ í˜•íƒœ ë“±ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ìš”ì•½í•˜ê²Œ ëœë‹¤.  

## 1. ì¤‘ì‹¬ê²½í–¥ì¹˜

**ì¤‘ì‹¬ê²½í–¥ì¹˜(central tendency)**ëŠ” ìë£Œ ë¶„í¬ì˜ ì¤‘ì‹¬ì„ ë³´ì—¬ì£¼ëŠ” ì¸¡ë„ë¡œ, ëŒ€í‘œê°’ì´ë¼ê³ ë„ í•œë‹¤. ë°ì´í„° ë¶„ì„ì„ í†µí•´ ìœ ì¶”í•˜ê³ ì í•˜ëŠ” ëª¨ìˆ˜, ì¦‰ ê´€ì‹¬ ëª¨ìˆ˜ì— ë”°ë¼ ì‚¬ìš©í•  ëŒ€í‘œê°’ì„ ì„ íƒí•˜ê²Œ ëœë‹¤.  

ìë£Œì—ì„œ ëŒ€ë¶€ë¶„ì˜ ê´€ì¸¡ê°’ìœ¼ë¡œë¶€í„° ë©€ë¦¬ ë–¨ì–´ì§„ ì¼ë¶€ ê´€ì¸¡ê°’ì„ **ì´ìƒì (outlier)**ì´ë¼ê³  í•˜ëŠ”ë°, ì´ìƒì ì˜ í¬í•¨ ì—¬ë¶€ì— ë”°ë¼ ì¤‘ì‹¬ê²½í–¥ì¹˜ì˜ ë³€ë™ì´ ì‹¬í•œ ê²½ìš° ì´ìƒì ì— ê°•ê±´(robust)í•˜ì§€ ì•Šë‹¤ê³  í‘œí˜„í•œë‹¤.  

### 1-1. í‰ê· 

**í‘œë³¸í‰ê· **

ìˆ˜ì¹˜í˜• ìë£Œì—ì„œ ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” ì¤‘ì‹¬ê²½í–¥ì¹˜ì— ëŒ€í•œ í†µê³„ê°’ì€ **í‰ê· (mean)**ìœ¼ë¡œ, í†µê³„í•™ì—ì„œëŠ” ìë£Œì˜ ë¬´ê²Œì¤‘ì‹¬ì„ ì˜ë¯¸í•˜ëŠ” í‘œë³¸í‰ê· ì„ ì˜ë¯¸í•œë‹¤. **í‘œë³¸í‰ê· (sample mean, $$\overline{x}$$)**ì„ êµ¬í•˜ëŠ” ê³µì‹ì€ ì•„ë˜ì™€ ê°™ë‹¤.  

$$\begin{gathered}
\sum_{i=1}^{m}(\overline{x} - x_{i}) = \sum_{i=m + 1}^{n}(x_{i} - \overline{x}) \\
\\
\Rightarrow \sum_{i=1}^{n}(x_{i} - \overline{x}) = 0 \\
\\
\therefore \overline{x} = \frac{1}{n} \sum_{i=1}^{n}x_{i}
\end{gathered}$$

ìœ„ ê³µì‹ì„ Pythonìœ¼ë¡œ êµ¬í˜„í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.  

```python
numeric = list[int | float]


def bar(data: numeric) -> float:
    """returns expectation/sample mean"""

    return sum(data) / len(data)
```

ì•„ë˜ì™€ ê°™ì´ NumPyë‚˜ Python ê¸°ë³¸ ëª¨ë“ˆ statisticsë¥¼ ì‚¬ìš©í•´ì„œ ì‰½ê²Œ êµ¬í•  ìˆ˜ ìˆë‹¤.  

```python
import statistics as stats
import numpy as np

data = [1, 2, 3, 4, 5, 6, 7, 8, 11, 13, 15]

mean = stats.mean(data)
mean = np.mean(data)
```

í‘œë³¸í‰ê· ì„ êµ¬í•˜ëŠ” ê³¼ì •ì—ì„œ $$i$$ ë²ˆì§¸ í‘œë³¸ì˜ **í¸ì°¨(deviation)**ë¥¼ ì•„ë˜ì™€ ê°™ì´ êµ¬í•  ìˆ˜ ìˆë‹¤.  

$$\text{deviation} = x_{i} - \overline{x}$$

ì£¼ì–´ì§„ ë°ì´í„°ì˜ ê° ìš”ì†Œë“¤ì˜ í‘œë³¸í‰ê· ì— ëŒ€í•œ í¸ì°¨ë¥¼ êµ¬í•˜ëŠ” ê³µì‹ì„ Pythonìœ¼ë¡œ êµ¬í˜„í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.  

```python
numeric = list[int | float]


def devi(data: numeric) -> dict:
    """returns deviation of each value"""

    return {val: val - bar(data) for val in sorted(list(set(data)))}
```

**ê°€ì¤‘í‰ê· **

í‘œë³¸í‰ê· ì€ ì´ìƒì (outlier)ì— robustí•˜ì§€ ì•Šë‹¤ëŠ” ë‹¨ì ì´ ìˆê¸° ë•Œë¬¸ì—, ì´ ë¶€ë¶„ì„ ê³ ë ¤í•´ì•¼í•  ê²½ìš° ê° ìë£Œì˜ ì¤‘ìš”ë„ë‚˜ ì˜í–¥ ì •ë„ì— í•´ë‹¹í•˜ëŠ” ê°€ì¤‘ì¹˜ë¥¼ ë°˜ì˜í•˜ì—¬ êµ¬í•œ í‰ê· ê°’ì¸ **ê°€ì¤‘í‰ê· (weighted mean)**ì„ ì‚¬ìš©í•œë‹¤. ê° ìš”ì†Œì˜ ê°€ì¤‘ì¹˜ë¥¼ $$w_{i}$$ë¼ í•  ë•Œ ê°€ì¤‘í‰ê· ì„ êµ¬í•˜ëŠ” ê³µì‹ì€ ì•„ë˜ì™€ ê°™ë‹¤.  

$$\overline{x}_{W} = \frac{1}{W} \sum_{i=1}^{n}w_{i}x_{i}$$

ê°€ì¤‘í‰ê·  êµ¬í•˜ëŠ” ê³µì‹ì„ Pythonìœ¼ë¡œ êµ¬í˜„í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.  

```python
numeric = list[int | float]


def mean_weight(data: numeric, weights: numeric) -> float:
    """returns weighted mean"""

    return sum(v * w for v, w in zip(data, weights)) / sum(weights)
```

ì•„ë˜ì™€ ê°™ì´ NumPyë‚˜ Python ê¸°ë³¸ ëª¨ë“ˆ statisticsë¥¼ ì‚¬ìš©í•´ì„œ ì‰½ê²Œ êµ¬í•  ìˆ˜ ìˆë‹¤.  

```python
import statistics as stats
import numpy as np

data = [1, 2, 3, 4, 5]
weights = [5, 4, 3, 2, 1]

weighted_mean = stats.fmean(data=data, weights=weights)
weighted_mean = np.average(a=data, weights=weights)
```

**ê¸°í•˜í‰ê· **

ì—°ì†ì ì¸ ë³€í™”ìœ¨ì— ëŒ€í•œ ìë£Œì—ì„œ íŠ¹ì • êµ¬ê°„ì—ì„œì˜ í‰ê·  ë³€í™”ìœ¨ì„ êµ¬í•  ë•ŒëŠ” ê´€ì¸¡ì¹˜ë¥¼ ëª¨ë‘ ê³±í•œ ê²°ê³¼ì˜ $$n$$ ì œê³±ê·¼ì¸ **ê¸°í•˜í‰ê· (geometric mean)**ì„ ì‚¬ìš©í•´ì•¼ í•˜ë©°, ê¸°í•˜í‰ê· ì„ êµ¬í•˜ëŠ” ê³µì‹ì€ ì•„ë˜ì™€ ê°™ë‹¤.  

$$\begin{align*}
\overline{x}_{G} & = \left( \prod_{i=1}^{n}x_{i} \right)^{1 / n} \\
\\
& = (x_{1} \times x_{2} \times \cdots \times x_{n})^{1 / n}, \quad x_{i} > 0
\end{align*}$$

ê¸°í•˜í‰ê·  êµ¬í•˜ëŠ” ê³µì‹ì„ Pythonìœ¼ë¡œ êµ¬í˜„í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.  

```python
numeric = list[int | float]


def production(data: numeric) -> float:
    """product all elements in data with for loop"""

    res = 1
    for i in data:
        res *= i
    return res


def mean_geom(data: numeric) -> float:
    """returns geometric mean of data"""

    return production(data) ** (1 / len(data))
```

ì•„ë˜ì™€ ê°™ì´ SciPyë‚˜ Python ê¸°ë³¸ ëª¨ë“ˆ statisticsë¥¼ ì‚¬ìš©í•´ì„œ ì‰½ê²Œ êµ¬í•  ìˆ˜ ìˆë‹¤.  

```python
import statistics as stats
from scipy.stats.mstats import gmean

data = [1, 2, 3, 4, 5]

geometric_mean = stats.geometric_mean(data)
geometric_mean = gmean(data)
```

**ì¡°í™”í‰ê· **

ë‘ ìë£Œì˜ í‰ê· ì ì¸ ë¹„ìœ¨ì„ êµ¬í•˜ê³  ì‹¶ì„ ë•ŒëŠ” ê° ìë£Œì˜ ì—­ìˆ˜ì˜ ì‚°ìˆ í‰ê· ì˜ ì—­ìˆ˜ì¸ **ì¡°í™”í‰ê· (harmonic mean)**ì„ ì‚¬ìš©í•´ì•¼í•œë‹¤.  

$$\begin{align*}
\overline{x}_{H} & = \left( \frac{\sum_{i=1}^{n} x_{i}^{-1}}{n} \right)^{-1}\\
\\
& = \frac{n}{\frac{1}{x_{1}} + \frac{1}{x_{2}} + \cdots + \frac{1}{x_{n}}} = \frac{n}{\sum_{i=1}^{n} \frac{1}{x_{i}}}
\end{align*}$$

ì‹¤ë¬´ì ìœ¼ë¡œëŠ” êµ¬ê°„ë³„ í‰ê· ì†ë ¥ ìë£Œë¡œë¶€í„° ì „ì²´ êµ¬ê°„ì— ëŒ€í•œ í‰ê· ì†ë ¥ì„ êµ¬í•  ë•Œë‚˜, ë¶„ë¥˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ëª¨ë¸ì˜ F1-scoreë¥¼ ê³„ì‚°í•  ë•Œ ì‚¬ìš©í•œë‹¤.  

ì¡°í™”í‰ê·  êµ¬í•˜ëŠ” ê³µì‹ì„ Pythonìœ¼ë¡œ êµ¬í˜„í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.  

```python
numeric = list[int | float]


def mean_harm(data: numeric) -> float:
    """returns harmonic mean of data"""

    return len(data) / (sum(1 / v for v in data))
```

ì•„ë˜ì™€ ê°™ì´ SciPyë‚˜ Python ê¸°ë³¸ ëª¨ë“ˆ statisticsë¥¼ ì‚¬ìš©í•´ì„œ ì‰½ê²Œ êµ¬í•  ìˆ˜ ìˆë‹¤.  

```python
import statistics as stats
from scipy.stats import hmean

data = [1, 2, 3, 4, 5]

harmonic_mean = stats.harmonic_mean(data)
harmonic_mean = hmean(data)
```

**í‘œë³¸ì ˆì‚¬í‰ê· **

**í‘œë³¸ì ˆì‚¬í‰ê· ì€(sample trimmed mean)**ì€ í‘œë³¸í‰ê· ê³¼ í‘œë³¸ì¤‘ì•™ê°’ì˜ ì¥/ë‹¨ì ì„ ì ì ˆíˆ ì·¨í•©í•œ ëŒ€í‘œê°’ìœ¼ë¡œ, $$\alpha$$%ì˜ í‘œë³¸ì ˆì‚¬í‰ê· ì€ ìˆœì„œí†µê³„ëŸ‰ì—ì„œ í•˜ìœ„ $$\alpha$$%ì—ì„œë¶€í„° ìƒìœ„ $$\alpha$$%ê¹Œì§€ì˜ ìë£Œë¥¼ ì´ìš©í•˜ì—¬ í‘œë³¸í‰ê· ì„ ê³„ì‚°í•œ ì¤‘ì‹¬ê²½í–¥ì¹˜ë‹¤. ë”°ë¼ì„œ $$\alpha$$ë¥¼ ì ì ˆíˆ ì¡°ì ˆí•˜ì—¬ ì´ìƒì ì„ ì œì™¸í•˜ë©´ì„œ ìµœëŒ€í•œ ë§ì€ í‘œë³¸ì •ë³´ë¥¼ ì´ìš©í•  ìˆ˜ ìˆë‹¤.  

ì‹¤ë¬´ì ìœ¼ë¡œëŠ” ì•„ë˜ì™€ ê°™ì´ ì „ì²´ $$n$$ê°œì˜ ìë£Œ ì¤‘ ê°€ì¥ ì‘ì€ $$k$$ê°œì™€ ê°€ì¥ í° $$k$$ê°œë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ $$n - 2k$$ê°œì— ëŒ€í•œ í‘œë³¸í‰ê· ì„ êµ¬í•˜ì—¬ ì‚¬ìš©í•œë‹¤.  

$$\text{trimmed mean} = \frac{x_{(k + 1)} + \cdots + x_{(n - k)}}{n - 2k}$$

í‘œë³¸ì ˆì‚¬í‰ê· ì„ Pythonìœ¼ë¡œ êµ¬í˜„í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.  

```python
numeric = list[int | float]


def mean_trimmed(data: numeric, k: int) -> float:
    """return trimmed mean from data, k defines number of data to trim"""

    return bar(sorted(data)[k:-k])
```

ì•„ë˜ì™€ ê°™ì´ SciPyë¥¼ ì´ìš©í•´ì„œë„ ì‰½ê²Œ ê³„ì‚°í•  ìˆ˜ ìˆëŠ”ë°, ì´ë¡ ëŒ€ë¡œ ì¼ì • ë¹„ìœ¨ì— ë”°ë¼ ë°ì´í„°ë¥¼ ì˜ë¼ë‚¸ë‹¤. [ê³µì‹ ë¬¸ì„œ](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.trim_mean.html)ì— ë”°ë¥´ë©´ ì ˆì‚¬í•  ìˆ«ìê°€ ì •ìˆ˜ê°€ ì•„ë‹ ê²½ìš° ì†Œìˆ˜ì ì„ ë²„ë¦°ë‹¤ê³  í•œë‹¤.  

```python
from scipy.stats import trim_mean

data = [1, 2, 3, 4, 5]

trim_mean = trim_mean(a=data, proportiontocut=0.1)
```

ğŸ’¡ì°¸ê³ ë¡œ í•˜ìœ„ $$\alpha$$%ì— í•´ë‹¹í•˜ëŠ” ê°’ì„ $$\alpha$$ ë°±ë¶„ìœ„ìˆ˜(percentile)ë¼ê³  í•˜ë©°, $$p = \alpha / 100$$ì¼ ë•Œ, $$p$$ [ë¶„ìœ„ìˆ˜(quantile)](#2-2-ì‚¬ë¶„ìœ„ê°„-ë²”ìœ„)ì´ë¼ê³  ë§í•œë‹¤.  
{:.note}

### 1-2. í‘œë³¸ì¤‘ì•™ê°’

ìë£Œë¥¼ í¬ê¸° ìˆœì„œëŒ€ë¡œ ë‚˜ì—´í–ˆì„ ë•Œ ì¤‘ê°„ì— ìˆëŠ” ê°’ì„ **í‘œë³¸ì¤‘ì•™ê°’(sample median, $$\widetilde{x}$$)**ì´ë¼ í•œë‹¤. í‘œë³¸ì¤‘ì•™ê°’ì€ í‘œë³¸ì„ ì˜¤ë¦„ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•œ ìˆœì„œí†µê³„ëŸ‰(order statistics)ë¥¼ í†µí•´ì„œ êµ¬í•  ìˆ˜ ìˆìœ¼ë©°, ì¼ë°˜ì‹ì€ ì•„ë˜ì™€ ê°™ë‹¤.  

$$\widetilde{x} = \begin{cases}
x_{(\frac{n + 1}{2})}, & x= \text{odd} \\
\\
(x_{(\frac{n}{2})} + x_{(\frac{n}{2} + 1)}) / 2, & x= \text{even}
\end{cases}$$

ì¤‘ì•™ê°’ì€ ê·¹ë‹¨ì ì¸ ê°’ì— ì˜í–¥ì„ ë°›ì§€ ì•Šì•„ ì•ˆì •ì ì¸ ì¤‘ì‹¬ê²½í–¥ì¹˜ë¥¼ ì œê³µí•˜ê¸° ë•Œë¬¸ì— ì´ìƒì ì— ëŒ€í•´ ê°•ê±´í•˜ë‹¤ëŠ” ì¥ì ì´ ìˆì§€ë§Œ, ìë£Œì˜ ëŒ€ë¶€ë¶„ì˜ ê°’ë“¤ì„ ìˆœì„œí†µê³„ëŸ‰ì„ êµ¬í•  ë•Œë§Œ ì´ìš©í•˜ê¸° ë•Œë¬¸ì— ìë£Œì˜ ì •ë³´ë¥¼ ë‹¤ í™œìš©í•˜ì§€ ëª»í•˜ë‹¤ëŠ” ë‹¨ì ì´ ìˆë‹¤.  

ì¤‘ì•™ê°’ êµ¬í•˜ëŠ” í•¨ìˆ˜ë¥¼ Pythonìœ¼ë¡œ êµ¬í˜„í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.  

```python
numeric = list[int | float]


def median(data: numeric) -> float:
    """returns median number of data"""

    data = sorted(data)
    n = len(data)
    if n % 2 == 0:
        i = int(n / 2)
        return sum([data[i], data[i - 1]]) / 2
    else:
        return data[int((n + 1) / 2) - 1]
```

ì•„ë˜ì™€ ê°™ì´ NumPyë‚˜ Python ê¸°ë³¸ ëª¨ë“ˆ statisticsë¥¼ ì‚¬ìš©í•´ì„œ ì‰½ê²Œ êµ¬í•  ìˆ˜ ìˆë‹¤.  

```python
import statistics as stats
import numpy as np

data_odd = [1, 2, 3, 4, 5]
data_even = [1, 2, 3, 4, 5, 6]

median_odd, median_even = stats.median(data_odd), stats.median(data_even)
median_odd, median_even = np.median(data_odd), np.median(data_even)
```

### 1-3. í‘œë³¸ìµœë¹ˆê°’

**í‘œë³¸ìµœë¹ˆê°’(sample mode)**ì€ ìë£Œ ì¤‘ ë¹ˆë„ê°€ ê°€ì¥ ë§ì€ ê°’ìœ¼ë¡œ, ìë£Œì˜ íŠ¹ì„±ì— ë”°ë¼ ì—¬ëŸ¬ ê°œê°€ ìˆê±°ë‚˜ ì „í˜€ ì—†ì„ ìˆ˜ë„ ìˆë‹¤. ìµœë¹ˆê°’ì€ íˆìŠ¤í† ê·¸ë¨ì—ì„œ ê°€ì¥ ë†’ì€ ë°€ë„ì˜ ì§€ì ì„ ë‚˜íƒ€ë‚¸ë‹¤. ìµœë¹ˆê°’ êµ¬í•˜ëŠ” í•¨ìˆ˜ë¥¼ Pythonìœ¼ë¡œ êµ¬í˜„í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.  

```python
numeric = list[int | float]


def mode(data: numeric) -> list | None:
    """returns mode value from data"""

    cnt = {v: data.count(v) for v in set(data)}
    cntmax = max(cnt.values())
    if cntmax == 1:
        return None
    else:
        return [v for v in cnt if cnt[v] == cntmax]
```

ì•„ë˜ì™€ ê°™ì´ SciPyë‚˜ Python ê¸°ë³¸ ëª¨ë“ˆ statisticsë¥¼ ì´ìš©í•˜ì—¬ ì‰½ê²Œ êµ¬í•  ìˆ˜ ìˆê¸´í•œë°, ë‘˜ ëª¨ë‘ ìµœë¹ˆê°’ì´ ì—¬ëŸ¬ ê°œ ìˆì„ ê²½ìš° í•˜ë‚˜ë§Œ ì•Œë ¤ì£¼ê³ , ìµœë¹ˆê°’ì´ ì—†ì–´ë„ ë­”ê°€ í•˜ë‚˜ë¥¼ ì•Œë ¤ì£¼ê¸´ í•œë‹¤. ì˜ë„ëœ ê²ƒ ê°™ì€ë°, ì™œì§€..?  

```python
import statistics as stats
from scipy.stats import mode

mode_even = [1, 1, 1, 2, 2, 3, 3, 3, 4, 4]
mode_odd = [1, 2, 3, 4, 5]

mode_even, mode_odd = stats.mode(mode_even), stats.mode(mode_odd)
mode_even, mode_odd = mode(mode_even), mode(mode_odd)
```

## 2. ì‚°í¬

**ì‚°í¬(dispersion)**ëŠ” ìë£Œë“¤ì´ ì–¼ë§ˆë‚˜ í¼ì ¸ ìˆëŠ”ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì¸¡ë„ë¡œ, ì‚°í¬ë¥¼ í†µí•´ ì¤‘ì‹¬ê²½í–¥ì¹˜ê°€ ì–¼ë§ˆë‚˜ ì•ˆì •ì ì¸ì§€ì— ëŒ€í•œ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤.  

- ì‚°í¬ê°€ ë‚®ìŒ = ì¤‘ì‹¬ê²½í–¥ì¹˜ì˜ ë³€ë™ì„± ë‚®ìŒ
- ì‚°í¬ê°€ ë†’ìŒ = ì¤‘ì‹¬ê²½í–¥ì¹˜ì˜ ë³€ë™ì„± ë†’ìŒ

### 2-1. ë²”ìœ„

**ë²”ìœ„(range)**ëŠ” ì•„ë˜ì™€ ê°™ì´ ìë£Œ ì¤‘ ê°€ì¥ í° ê°’ê³¼ ì‘ì€ ê°’ì˜ ì°¨ì´ë¥¼ ë§í•œë‹¤. ìë£Œì˜ êµ¬ì¡°ì— ì˜í–¥ì„ ë°›ì§€ ì•Šê¸° ë•Œë¬¸ì— ì •í™•í•œ ì •ë³´ íŒŒì•…ì´ í˜ë“¤ê³ , ì´ìƒì¹˜ì— ê°•ê±´í•˜ì§€ ëª»í•˜ë‹¤ëŠ” ë‹¨ì ì´ ìˆë‹¤.  

$$\text{range} = x_{max} - x_{min}$$

Pythonìœ¼ë¡œ êµ¬í˜„í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.  

```python
numeric = list[int | float]


def data_range(data: numeric) -> float:
    """returns range of data"""

    return max(data) - min(data)
```

### 2-2. ì‚¬ë¶„ìœ„(ê°„) ë²”ìœ„

ìë£Œë¥¼ ì•„ë˜ì™€ ê°™ì´ ë™ì¼í•œ ë¹„ìœ¨ë¡œ 4ë“±ë¶„ í•  ë•Œì˜ ì„¸ ìœ„ì¹˜ë¥¼ **ì‚¬ë¶„ìœ„ìˆ˜(quartile)**ë¼í•˜ê³ , ì‚¬ë¶„ìœ„ìˆ˜ë¥¼ í™œìš©í•œ ì‚°í¬ ë²”ìœ„ ê³„ì‚°ì„ **ì‚¬ë¶„ìœ„(ê°„) ë²”ìœ„(interquartile range, IQR)**ë¼ í•œë‹¤.  

- 25% ì§€ì : ì œ1ì‚¬ë¶„ìœ„ìˆ˜($$Q_{1}$$)
- 50% ì§€ì : ì œ2ì‚¬ë¶„ìœ„ìˆ˜($$Q_{2}$$), [í‘œë³¸ì¤‘ì•™ê°’](#1-2-í‘œë³¸ì¤‘ì•™ê°’)ê³¼ ë™ì¼
- 75% ì§€ì : ì œ3ì‚¬ë¶„ìœ„ìˆ˜($$Q_{3}$$)

ì‚¬ë¶„ìœ„(ê°„) ë²”ìœ„ëŠ” ì•„ë˜ì™€ ê°™ë‹¤.  

$$IQR = Q_{3} - Q_{1}$$

**ë¶„ìœ„ìˆ˜(quantile)**ëŠ” ì•„ë˜ ì‚°ì‹ì—ì„œ $$k$$ê°€ ì •ìˆ˜ì¼ ê²½ìš° $$x_{k}$$, ì •ìˆ˜ê°€ ì•„ë‹ ê²½ìš° $$x_{\lceil k \rceil}, x_{\lfloor k \rfloor}$$ ì‚¬ì´ì˜ ë¹„ë¡€ì— ì˜í•œ ë‚´ì‚½ë²•ì„ ì ìš©í•˜ì—¬ ê³„ì‚°í•˜ëŠ”ë°, ì‚¬ë¶„ìœ„ìˆ˜ì˜ ê²½ìš° $$p$$ì— $$0.25, 0.5, 0.75$$ë¥¼ ëŒ€ì…í•˜ë©´ ëœë‹¤.  

$$k = (n - 1)p + 1$$

ë¶„ìœ„ìˆ˜ êµ¬í•˜ëŠ” í•¨ìˆ˜ì™€ ì‚¬ë¶„ìœ„ ë²”ìœ„ êµ¬í•˜ëŠ” í•¨ìˆ˜ë¥¼ Pythonìœ¼ë¡œ êµ¬í˜„í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.  

```python
numeric = list[int | float]


def quantile(data: numeric, q: float) -> float:
    """returns quantile value from data"""

    data = sorted(data)
    k = (len(data) - 1) * q
    i = int(k)
    r = k - i
    return data[i] * (1 - r) + data[i + 1] * r


def iqr_range(data: numeric) -> float:
    """returns IQR range from data"""

    return quantile(data, 0.75) - quantile(data, 0.25)
```

ì•„ë˜ì™€ ê°™ì´ NumPyë‚˜ Python ê¸°ë³¸ ëª¨ë“ˆ statisticsë¥¼ ì‚¬ìš©í•´ì„œ ì‰½ê²Œ êµ¬í•  ìˆ˜ ìˆë‹¤. statistics ëª¨ë“ˆì˜ ê²½ìš° `method` íŒŒë¼ë¯¸í„°ë¥¼ `inclusive`ë¡œ ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ë°ì´í„°ë¥¼ í‘œë³¸ì§‘ë‹¨ìœ¼ë¡œ ì¸ì‹í•˜ê¸° ë•Œë¬¸ì— ê³„ì‚°ì´ ì¡°ê¸ˆ ë‹¬ë¼ì§„ë‹¤.  

```python
import statistics as stats
import numpy as np

data = [1, 2, 3, 4, 5, 6, 7, 8]
q = [0.25, 0.5, 0.75]

quantiles = stats.quantiles(data, method='inclusive')
quantiles = [np.quantile(a=data, q=q) for q in q]
```

ì‚¬ë¶„ìœ„ìˆ˜ëŠ” box plotì„ í†µí•´ ìë£Œì˜ [ì´ìƒì ì„ íŒŒì•…](/dataanalysis/iqr_method/)í•˜ëŠ”ë° ì£¼ë¡œ ì‚¬ìš©ëœë‹¤.  

### 2-3. ê±°ë¦¬ì™€ ì‚°í¬

#### ê±°ë¦¬

í‘œë³¸ë¶„ì‚°ê³¼ í‘œë³¸í‘œì¤€í¸ì°¨ë¥¼ ì´í•´í•˜ê¸° ìœ„í•´ì„œëŠ” **ê±°ë¦¬(distance, $$D$$)**ë¼ëŠ” ê°œë…ì„ ë¨¼ì € ì´í•´í•  í•„ìš”ê°€ ìˆëŠ”ë°, ìˆ˜í•™ì ìœ¼ë¡œëŠ” ì„ì˜ì˜ ì„¸ ì  $$a, b, c$$ì— ëŒ€í•´ ì•„ë˜ ì„¸ ì¡°ê±´ì„ ë§Œì¡±í•  ë•Œ ê±°ë¦¬ë¼ê³  í•œë‹¤.  

- $$a = b$$ ì´ë©´ $$D(a, b) = 0$$ ì´ê³ , ê·¸ ì—­ë„ ì„±ë¦½í•  ê²ƒ
- $$D(a, b) = D(b, a)$$ ì¼ ê²ƒ
- $$D(a, b) \le D(a, c) + D(c, b)$$ ì¼ ê²ƒ

í†µê³„í•™ì—ì„œ ë§ì´ ì‚¬ìš©í•˜ëŠ” ê±°ë¦¬ëŠ” ì•„ë˜ ì¢…ë¥˜ë“¤ì´ ìˆë‹¤.  

$$D(a, b) =  \vert a - b \vert, \quad D(a, b) = (a - b)^{2}$$

ğŸ’¡$$D(a, b) = (a - b)^{2}$$ ì´ ì„±ë¦½í•˜ëŠ” ì´ìœ ëŠ”, ì—¬ê¸°ì„œ ë§í•˜ëŠ” **ê±°ë¦¬**ê°€ ë²¡í„°ì˜ í¬ê¸°([norm](/mathematics/linear_algebra_07/#2-ë…¸ë¦„norm))ë¥¼ ì˜ë¯¸í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆê¸° ë•Œë¬¸ì´ë‹¤. ë°ì´í„°ì˜ ì‚°í¬ë¥¼ ìˆ˜í•™ì ìœ¼ë¡œ ê³„ì‚°í•˜ê¸° ìœ„í•´ì„œ **ê±°ë¦¬**ë¥¼ ì‚¬ìš©í•  ë•Œ, í° ê²ƒì€ í¬ê²Œ ì‘ì€ ê²ƒì€ ì‘ê²Œ ê³„ì‚°ë˜ëŠ” ë¶€ë¶„ì— ë³€ë™ì´ ì—†ë‹¤ë©´ ì œê³±ê·¼ì„ í•˜ë‚˜ ì¤„ì—¬ ê³„ì‚°ì„ ê°„ê²°í•˜ê²Œ í•˜ëŠ” ê²ƒì´ ë” ì¢‹ë‹¤.  
{:.note}

ë”°ë¼ì„œ ìœ„ ì •ë¦¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ ëª¨ë“  ê´€ì¸¡ê°’ë“¤ ê°„ ê±°ë¦¬ì˜ í•©ì„ í‘œí˜„í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.  

$$\sum_{i=1}^{n}\sum_{j=1}^{n} \vert x_{i} - x_{j} \vert, \quad \sum_{i=1}^{n}\sum_{j=1}^{n}(x_{i} - x_{j})^{2}$$

ìœ„ ì •ë¦¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¤‘ì‹¬ê²½í–¥ì¹˜ $$a$$ì™€ ëª¨ë“  ê´€ì¸¡ê°’ë“¤ ê°„ ê±°ë¦¬ì˜ í•©ì€ ì•„ë˜ì™€ ê°™ì´ í‘œí˜„í•  ìˆ˜ ìˆë‹¤.  

$$L_{1}(a) = \sum_{i=1}^{n} \vert x_{i} - a \vert, \quad L_{2}(a) = \sum_{i=1}^{n}(x_{i} - a)^{2}$$

ì´ ë•Œ, $$a$$ì˜ ì ì ˆí•œ ìœ„ì¹˜, ì¦‰ ìë£Œë¥¼ ê°€ì¥ ì˜ ëŒ€í‘œí•  ìˆ˜ ìˆëŠ” ì¤‘ì‹¬ê²½í–¥ì¹˜ëŠ” **ê±°ë¦¬ì˜ í•©ì„ ìµœì†Œí™”** í•˜ëŠ”(í¸ì°¨ì˜ í•©ì´ 0ì¸) ì§€ì ìœ¼ë¡œ, ì•„ë˜ì™€ ê°™ì´ ì •ë¦¬í•  ìˆ˜ ìˆë‹¤.  

- $$L_{1}(a)$$ì˜ ê²½ìš° [í‘œë³¸ì¤‘ì•™ê°’](#1-2-í‘œë³¸ì¤‘ì•™ê°’)($$a = \widetilde{x}$$)ì—ì„œ ìµœì†Œí™”ëœë‹¤.
- $$L_{2}(a)$$ì˜ ê²½ìš° [í‘œë³¸í‰ê· ](#í‘œë³¸í‰ê· )($$a = \overline{x}$$)ì—ì„œ ìµœì†Œí™”ë˜ë©°, $$L_{2}(a)$$ë¥¼ $$a$$ì— ëŒ€í•´ ë¯¸ë¶„í•œ ë¯¸ë¶„ê³„ìˆ˜ê°€ 0ì´ ë˜ëŠ” $$a$$ ê°’ì´ ê±°ë¦¬ì˜ í•©ì´ ìµœì†Œí™” ë˜ëŠ” ì§€ì ì´ê¸° ë•Œë¬¸ì— ì•„ë˜ì™€ ê°™ì´ ìœ ë„í•  ìˆ˜ ìˆë‹¤.

$$\begin{gathered}
\frac{\text{d}L_{2}(a)}{\text{d} a} = -2\sum_{i=1}^{n}(x_{i} - a) = 0 \\
\\
\Rightarrow a = \frac{1}{n}\sum_{i=1}^{n}x_{i} = \overline{x}
\end{gathered}$$

ìœ„ ì •ë¦¬ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ, ê±°ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìë£Œì˜ ì‚°í¬ë„ë¥¼ ê³„ì‚°í•˜ë©´ ì•„ë˜ì™€ ê°™ê³ , íŠ¹íˆ $$L_{2}$$ì˜ ê²½ìš° í¸ì°¨ì˜ ì œê³±í•©ìœ¼ë¡œ ì •ë¦¬í•  ìˆ˜ ìˆë‹¤.  

$$L_{1}(\widetilde{x}) = \sum_{i=1}^{n} \vert x_{i} - \widetilde{x} \vert, \quad L_{2}(\overline{x}) = \sum_{i=1}^{n}(x_{i} - \overline{x})^{2}$$

#### í‘œë³¸ë¶„ì‚°

$$L_{1}(\widetilde{x})$$ì™€ $$L_{2}(\overline{x})$$ì˜ ê²½ìš°ì—ëŠ” ìë£Œì˜ ê°œìˆ˜ê°€ ë§ì•„ì§ˆìˆ˜ë¡ ì»¤ì§ˆ ìˆ˜ë°–ì— ì—†ê¸° ë•Œë¬¸ì—, ì´ë¥¼ ë³´ì •í•˜ê¸° ìœ„í•´ í‘œë³¸ì˜ í¬ê¸°ë¡œ ë³´ì •ì„ í•˜ê²Œ ë˜ëŠ”ë°, ì´ë¥¼ **í‘œë³¸ë¶„ì‚°(sample variance)**ì´ë¼ê³  í•˜ê³  ì•„ë˜ì™€ ê°™ì´ ê³„ì‚°í•œë‹¤.  

$$s^{2} = \frac{1}{n - 1}\sum_{i=1}^{n}(x_{i} - \overline{x})^{2}$$

<details><summary>í‘œë³¸ë¶„ì‚°ì˜ ê°„í¸ì‹ê³¼ ê·¸ ìœ ë„</summary><div markdown="1">

$$\begin{align*}
s^{2} & = \frac{1}{n - 1}\sum_{i=1}^{n}(x_{i} - \overline{x})^{2} \\
& = \frac{1}{n - 1}\sum_{i=1}^{n}(x_{i}^{2} - 2x_{i}\overline{x} + \overline{x}^{2}) \\
& = \frac{1}{n - 1} \left( \sum_{i=1}^{n}x_{i}^{2} - 2\overline{x}\sum_{i=1}^{n}x_{i} + n\overline{x}^{2} \right) \\
& = \frac{1}{n - 1} \left( \sum_{i=1}^{n}x_{i}^{2} -2n\overline{x}^{2} + n\overline{x}^{2} \right) \quad \because \sum_{i=1}^{n}x_{i} = n\overline{x} \\
& = \frac{1}{n - 1} \left( \sum_{i=1}^{n}x_{i}^{2} - n\overline{x}^{2} \right) \\
& = \frac{1}{n - 1} \left\{ \sum_{i=1}^{n}x_{i}^{2} - \frac{1}{n} \left( \sum_{i=1}^{n}x_{i} \right)^{2} \right\} \quad \because \overline{x} = \frac{1}{n}\sum_{i=1}^{n}x_{i}
\end{align*}$$

</div></details><br>

ì´ ë•Œ, $$n$$ì´ ì•„ë‹Œ $$n - 1$$ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì£¼ëŠ” ì´ìœ ëŠ” **ììœ ë„(degree of freedom)** ë•Œë¬¸ìœ¼ë¡œ, í‘œë³¸ë¶„ì‚°ì˜ ê²½ìš° $$\sum(x_{i} - \overline{x}) = 0$$ì´ë¼ëŠ” ì œì•½ì¡°ê±´ì´ ìˆê¸° ë•Œë¬¸ì— $$n - 1$$ê°œì˜ í¸ì°¨ ì •ë³´ë¥¼ ì‚¬ìš©í•œë‹¤.  

ğŸ’¡ììœ ë„(degree of freedom)ëŠ” **ë¹„í¸í–¥ì¶”ì •ëŸ‰/ë¶ˆí¸ì¶”ì •ëŸ‰(Unbiased Estimator)**ì„ ë§Œë“¤ì–´ì£¼ê¸° ìœ„í•´ ì‚¬ìš©ëœë‹¤.  
{:.note}

ë¶„ì‚°ì„ Pythonìœ¼ë¡œ êµ¬í˜„í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.  

```python
numeric = list[int | float]


def var(data: numeric, dof: int = 1) -> float:
    """returns variance of data"""

    return sum((d - bar(data)) ** 2 for d in data) / (len(data) - dof)
```

ì•„ë˜ì™€ ê°™ì´ NumPyë‚˜ Python ê¸°ë³¸ ëª¨ë“ˆ statisticsë¥¼ ì‚¬ìš©í•´ì„œ ì‰½ê²Œ êµ¬í•  ìˆ˜ ìˆë‹¤.  

```python
import statistics as stats
import numpy as np

data = [1, 2, 3, 4, 5, 6, 7, 8, 11, 13, 15]

variance = stats.variance(data)
variance = np.var(data, ddof=1)
```

#### í‘œë³¸í‘œì¤€í¸ì°¨

í‘œë³¸ë¶„ì‚°ì€ í¸ì°¨ì˜ ì œê³±í•©ì„ ì´ìš©í•˜ê¸° ë•Œë¬¸ì— ë¶„ì‚°ì˜ ë‹¨ìœ„ëŠ” ê´€ì¸¡ê°’ ë‹¨ìœ„ì˜ ì œê³±ì´ ëœë‹¤. ì´ë¡œ ì¸í•´ ë°œìƒí•˜ëŠ” ë°ì´í„°ì˜ ì™œê³¡ì„ ë§‰ê¸° ìœ„í•´ ì¼ë°˜ì ìœ¼ë¡œëŠ” í‘œë³¸ë¶„ì‚°ì˜ ì œê³±ê·¼ì¸ **í‘œë³¸í‘œì¤€í¸ì°¨(sample standard deviation)**ë¥¼ ì‚¬ìš©í•˜ê²Œ ëœë‹¤.  

$$s = \sqrt{s^{2}} = \sqrt{\frac{1}{n - 1}\sum_{i=1}^{n}(x_{i} - \overline{x})^{2}}$$

ìœ„ ê³µì‹ì„ Pythonìœ¼ë¡œ êµ¬í˜„í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.  

```python
numeric = list[int | float]


def std(data: numeric, dof: int = 1) -> float:
    """return standard deviation of data"""

    return var(data, dof) ** (1 / 2)
```

ì•„ë˜ì™€ ê°™ì´ NumPyë‚˜ Python ê¸°ë³¸ ëª¨ë“ˆ statisticsë¥¼ ì‚¬ìš©í•´ì„œ ì‰½ê²Œ êµ¬í•  ìˆ˜ ìˆë‹¤.  

```python
import statistics as stats
import numpy as np

data = [-5, -2, 1, 2, 3, 4, 5, 6, 7, 8, 11, 13, 15, 17, 19, 25, 87, 99, 100]

standard_deviation = stats.stdev(data)
standard_deviation = np.std(data, ddof=1)
```

#### í‘œì¤€í™”

ìë£Œë“¤ ê°„ì˜ ì²™ë„(scale)ë‚˜ ìœ„ì¹˜ê°€ ë‹¬ë¼ ë°ì´í„°ì— ì™œê³¡ì´ ìƒê¸°ëŠ” ê²½ìš°ë¥¼ ë§‰ê¸° ìœ„í•´ ë°ì´í„°ë¥¼ ë³€ê²½í•´ì£¼ëŠ” ì ˆì°¨ë¥¼ **í‘œì¤€í™”(standardization)**ì´ë¼ê³  í•˜ë©° ì•„ë˜ì™€ ê°™ì´ ê³„ì‚°í•œë‹¤.  

$$z_{i} = \frac{x_{i} - \overline{x}}{s_{x}} \quad \Rightarrow \quad x_{i} = s_{x}z_{i} + \overline{x}$$

í‘œì¤€í™”ë¥¼ í•˜ê²Œ ë˜ë©´ í‰ê· ì€ 0, ë¶„ì‚°ì€ 1ì´ ë˜ì–´ ì¸¡ì • ë‹¨ìœ„(scale)ì— ì˜í–¥ì„ ë°›ì§€ ì•Šê²Œ ì¤‘ì‹¬ìœ„ì¹˜ì™€ ì²™ë„ë¥¼ ì¡°ì •í•˜ê¸° ë•Œë¬¸ì— ë‹¤ì–‘í•œ ë°ì´í„°ì˜ ì ˆëŒ€ë¹„êµê°€ ê°€ëŠ¥í•´ì§„ë‹¤.  

$$\overline{z} = 0, \quad s_{z}^{2} = 1$$

ë°ì´í„°ë¥¼ í‘œì¤€í™” í•˜ëŠ” ê³µì‹ì„ Pythonìœ¼ë¡œ êµ¬í˜„í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.  

```python
numeric = list[int | float]


def standardize(num: float, bar: float, std: float) -> float:
    """standardize value"""

    return (num - bar) / std


def scaler_standard(data: numeric, dof: int = 0) -> list:
    """returns standardized values of data"""

    b, s = bar(data), std(data, dof)
    return [standardize(d, b, s) for d in data]
```

ì•„ë˜ì™€ ê°™ì´ scikit-learnì„ ì‚¬ìš©í•˜ë©´ í‘œì¤€í™”ë¥¼ ì‰½ê²Œ ì§„í–‰í•  ìˆ˜ ìˆë‹¤.  

```python
import numpy as np
from sklearn.preprocessing import StandardScaler

data = [-5, -2, 1, 2, 3, 4, 5, 6, 7, 8, 11, 13, 15, 17, 19, 25, 87, 99, 100]

scaler = StandardScaler()
scaled = scaler.fit_transform(np.array(data).reshape(-1, 1)).reshape(1, -1)
```

ğŸ’¡í‘œì¤€í™” ì™¸ì—ë„ ë‹¤ì–‘í•œ scaling ë°©ì‹ì´ ìˆë‹¤. [ê´€ë ¨ ë§í¬](/dataanalysis/scalers/) ì°¸ê³ 
{:.note}

### 2-4. ë³€ë™ê³„ìˆ˜

í‘œì¤€í¸ì°¨ê°€ í‰ê· ì— ì˜í–¥ì„ ë°›ëŠ” ê²½ìš° í‘œì¤€í¸ì°¨ë§Œ ì´ìš©í•˜ì—¬ ì‚°í¬ë¥¼ ë¹„êµí•˜ëŠ” ê²ƒì€ ì ì ˆí•˜ì§€ ì•Šì„ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— í‰ê· ìœ¼ë¡œ í‘œì¤€í¸ì°¨ë¥¼ ë³´ì •í•˜ëŠ” **ë³€ë™ê³„ìˆ˜(coefficient of variation)**ë¥¼ ì‚¬ìš©í•˜ë©°, ë³€ë™ê³„ìˆ˜($$CV$$)ëŠ” ì•„ë˜ì™€ ê°™ì´ ê³„ì‚°í•œë‹¤.  

$$CV = \frac{s}{\overline{x}}$$

ì•„ë˜ì™€ ê°™ì´ % ê°œë…ì„ ì‚¬ìš©í•˜ì—¬ í‘œë³¸í‰ê· ì— ë¹„í•´ í‘œë³¸í‘œì¤€í¸ì°¨ê°€ ì–¼ë§ˆë‚˜ í°ì§€ í‘œì‹œí•˜ê¸°ë„ í•œë‹¤.  

$$CV = \frac{s}{\overline{x}} \times 100$$

ë³€ë™ê³„ìˆ˜ êµ¬í•˜ëŠ” ê³µì‹ì„ Pythonìœ¼ë¡œ êµ¬í˜„í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.  

```python
numeric = list[int | float]


def variation(data: numeric, dof: int = 0) -> float:
    """returns coefficient of variation"""

    return std(data, dof) / bar(data)
```

ì•„ë˜ì™€ ê°™ì´ SciPyë¥¼ ì‚¬ìš©í•˜ë©´ ì‰½ê²Œ êµ¬í•  ìˆ˜ ìˆë‹¤.  

```python
from scipy import stats
from scipy.stats import mstats

data = [-5, -2, 1, 2, 3, 4, 5, 6, 7, 8, 11, 13, 15, 17, 19, 25, 87, 99, 100]

variation = stats.variation(data)
variation = mstats.variation(data)
```

## 3. ë¶„í¬ì˜ í˜•íƒœ

ë§ì€ í†µê³„ë¶„ì„ ë°©ë²•ì€ ëª¨ì§‘ë‹¨ì˜ ì¤‘ì‹¬ê²½í–¥ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ëŒ€ì¹­(symmetric), ì¦‰ ì •ê·œ ë¶„í¬í•˜ëŠ” ë°ì´í„°ë¼ê³  ê°€ì •í•˜ë©°, ë¶„ì„ ë°©ë²•ì˜ ì ì ˆì„±ì€ ê°€ì •í•œ ì¡°ê±´ì„ ìë£Œê°€ ì–¼ë§ˆë‚˜ ë§Œì¡±í•˜ê³  ìˆëŠ”ì§€ì— ë”°ë¼ ì˜í–¥ì„ ë°›ëŠ”ë‹¤.  

ë”°ë¼ì„œ ìë£Œì˜ ë¶„í¬ í˜•íƒœë¥¼ í™•ì¸í•˜ì—¬ ìë£Œê°€ ëª¨ì§‘ë‹¨ì˜ í˜•íƒœì™€ ìœ ì‚¬í•­ í˜•íƒœë¥¼ ê°€ì§€ê³  ìˆëŠ”ì§€, ì¦‰ ëª¨ì§‘ë‹¨ì˜ ê°€ì •ì„ ë§Œì¡±í•˜ëŠ”ì§€ í™•ì¸í•  í•„ìš”ê°€ ìˆìœ¼ë©°, ì´ ë•Œ ì‚¬ìš©í•˜ëŠ” ì¸¡ë„ë¡œ ì™œë„ì™€ ì²¨ë„ê°€ ìˆë‹¤.  

### 3-1. ì™œë„

**ì™œë„(skewness)**ëŠ” ìë£Œê°€ ëŒ€ì¹­ì ìœ¼ë¡œ ë¶„í¬ë˜ì–´ ìˆëŠ”ì§€, ë˜ëŠ” í•œìª½ìœ¼ë¡œ ì¹˜ìš°ì³ ìˆëŠ”ì§€ì— ëŒ€í•œ ì¸¡ë„ë¥¼ ë§í•˜ë©°, ì•„ë˜ ê³µì‹ê³¼ ê°™ì´ ê³„ì‚°í•œë‹¤.  

$$\sqrt{b_{1}} = \frac{1}{n - 1}\sum_{i=1}^{n} \left( \frac{x_{i} - \overline{x}}{s} \right)^{3}$$

ìë£Œì˜ ë¶„í¬ë¥¼ í™•ì¸í–ˆì„ ë•Œ ê¼¬ë¦¬ê°€ ê¸¸ê²Œ ë¶„í¬í•  ê²½ìš° ë‘í„°ìš´ ê¼¬ë¦¬(heavy tail)ë¥¼ ê°–ëŠ”ë‹¤ê³  í‘œí˜„í•œë‹¤. ì˜¤ë¥¸ìª½ ê¼¬ë¦¬ê°€ ê¸¸ ë•Œ(ì™œë„ê°€ í° ì–‘ìˆ˜ì¼ ë•Œ) ì˜¤ë¥¸ìª½ìœ¼ë¡œ skewed ë˜ì—ˆë‹¤(skewed to the right)ê³  í‘œí˜„í•˜ë©°, ë°˜ëŒ€ë¡œ ì™¼ìª½ ê¼¬ë¦¬ê°€ ê¸¸ ë•Œ(ì™œë„ê°€ í° ìŒìˆ˜ì¼ ë•Œ) ì™¸ìª½ìœ¼ë¡œ skewed ë˜ì—ˆë‹¤(skewed to the left)ê³  í‘œí˜„í•œë‹¤.  

ì™œë„ êµ¬í•˜ëŠ” í•¨ìˆ˜ë¥¼ Pythonìœ¼ë¡œ êµ¬í˜„í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.  

```python
numeric = list[int | float]


def skew(data: numeric, dof: int = 0) -> float:
    """returns skewness of data"""

    b, s = bar(data), std(data, dof)
    return sum(standardize(d, b, s) ** 3 for d in data) / (len(data) - dof)
```

ì•„ë˜ì™€ ê°™ì´ SciPyë¥¼ ì‚¬ìš©í•˜ë©´ ì‰½ê²Œ êµ¬í•  ìˆ˜ ìˆë‹¤. ë‹¤ë§Œ ë¹…ë°ì´í„°ë¥¼ ë‹¤ë£° ë•Œ ì‚¬ìš©í•  ê²ƒìœ¼ë¡œ ìƒê°í–ˆëŠ”ì§€ ììœ ë„ë¥¼ 0ìœ¼ë¡œ ê³„ì‚°í•œë‹¤.  

```python
from scipy.stats import skew

data = [-5, -2, 1, 2, 3, 4, 5, 6, 7, 8, 11, 13, 15, 17, 19, 25, 87, 99, 100]

skewness = skew(data)
```

ê²½ìš°ì— ë”°ë¼ ì•„ë˜ì™€ ê°™ì´ ìˆ˜ì •ëœ ì™œë„ë¥¼ ì‚¬ìš©í•˜ê¸°ë„ í•œë‹¤.  

$$\sqrt{b_{1}} = \frac{n}{(n - 1)(n - 2)}\sum_{i=1}^{n} \left( \frac{x_{i} - \overline{x}}{s} \right)^{3}$$

ìœ„ ê³µì‹ì„ Pythonìœ¼ë¡œ êµ¬í˜„í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.  

```python
numeric = list[int | float]


def skew_adv(data: numeric) -> float:
    """returns fixed skewness of data"""

    n = len(data)
    return skew(data, 1) * (n / n - 2)
```

### 3-2. ì²¨ë„

**ì²¨ë„(kurtosis)**ëŠ” ì¤‘ì‹¬ê²½í–¥ì¹˜ê°€ ì–¼ë§ˆë‚˜ ë¾°ì¡±í•œì§€ë¥¼ ì–‘ìª½ ê¼¬ë¦¬ì˜ ë‘í„°ìš´ ì •ë„ë¥¼ í†µí•´ ë‚˜íƒ€ë‚´ëŠ” ê°’ìœ¼ë¡œ, ì•„ë˜ ê³µì‹ê³¼ ê°™ì´ ê³„ì‚°í•œë‹¤.  

$$b_{2} = \frac{1}{n - 1}\sum_{i=1}^{n} \left( \frac{x_{i} - \overline{x}}{s} \right)^{4}$$

ì²¨ë„ëŠ” ê¼¬ë¦¬ë¶€ë¶„ì´ ì–¼ë§ˆë‚˜ ë‘í„°ìš´ì§€ì— ë”°ë¼ ì˜í–¥ì„ ë§ì´ ë°›ëŠ”ë°, ê¼¬ë¦¬ê°€ ê¸¸ìˆ˜ë¡ ì´ìƒì ì˜ ì¡´ì¬ ê°€ëŠ¥ì„±ì´ ë†’ê¸° ë•Œë¬¸ì´ë‹¤.  

ì •ê·œ ë¶„í¬ì˜ ê²½ìš° ì´ë¡ ì ìœ¼ë¡œ ì²¨ë„ê°€ 3ì´ê¸° ë•Œë¬¸ì— ë°ì´í„°ê°€ ì •ê·œ ë¶„í¬ë¥¼ ë”°ë¥¸ë‹¤ë©´ ì²¨ë„ ì—­ì‹œ 3ì— ê°€ê¹Œìš´ ê°’ì„ ê°–ê²Œ ëœë‹¤. ë”°ë¼ì„œ ì‹¤ë¬´ì—ì„œëŠ” ë§ì€ ê²½ìš°ì— ì•„ë˜ì™€ ê°™ì´ ê¸°ì¤€ì„ 3ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ 3ì„ ëº€ ê°’ì„ í™œìš©í•œë‹¤.  

$$b_{2} = \frac{1}{n - 1}\sum_{i=1}^{n} \left( \frac{x_{i} - \overline{x}}{s} \right)^{4} - 3$$

ì²¨ë„ êµ¬í•˜ëŠ” ê³µì‹ì„ Pythonìœ¼ë¡œ êµ¬í˜„í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.  

```python
numeric = list[int | float]


def kurtosis(data: numeric, dof: int = 0) -> float:
    """returns kurtosis of data"""

    b, s = bar(data), std(data, dof)
    return (sum(standardize(d, b, s) ** 4 for d in data) / (len(data) - dof))


def kurtosis_norm(data: numeric, dof: int = 0) -> float:
    """returns kurtosis of normal distributed data"""

    return kurtosis(data, dof) - 3
```

ì•„ë˜ì™€ ê°™ì´ SciPyë¥¼ ì‚¬ìš©í•˜ë©´ ì‰½ê²Œ ì²¨ë„ë¥¼ ì‰½ê²Œ êµ¬í•  ìˆ˜ ìˆë‹¤. ë§ˆì°¬ê°€ì§€ë¡œ ë¹…ë°ì´í„°ë¥¼ ë‹¤ë£° ë•Œ ì‚¬ìš©í•  ê²ƒìœ¼ë¡œ ìƒê°í–ˆëŠ”ì§€ ììœ ë„ë¥¼ 0ìœ¼ë¡œ ê³„ì‚°í•  ë¿ë§Œ ì•„ë‹ˆë¼ ì •ê·œ ë¶„í¬ë¥¼ ì „ì œí•˜ì—¬ -3ì´ ë°˜ì˜ëœ ê°’ì„ ë°˜í™˜í•œë‹¤.  

```python
from scipy.stats import kurtosis

data = [-5, -2, 1, 2, 3, 4, 5, 6, 7, 8, 11, 13, 15, 17, 19, 25, 87, 99, 100]

kurtosis = kurtosis(data)
```

ê²½ìš°ì— ë”°ë¼ ì•„ë˜ì™€ ê°™ì´ ìˆ˜ì •ëœ ì²¨ë„ë¥¼ ì‚¬ìš©í•˜ê¸°ë„ í•œë‹¤.  

$$b_{2} = \frac{n(n + 1)}{(n - 1)(n - 2)(n - 3)}\sum_{i=1}^{n} \left( \frac{x_{i} - \overline{x}}{s} \right)^{4} - \frac{3(n - 1)^{2}}{(n - 2)(n - 3)}$$

ìœ„ ê³µì‹ì„ Pythonìœ¼ë¡œ êµ¬í˜„í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.  

```python
numeric = list[int | float]


def kurtosis_adv(data: numeric) -> float:
    """returns fixed kurtosis of data"""

    k, n = kurtosis(data, 1), len(data)
    return (k * n * (n + 1) / ((n - 2) * (n - 3))) - ((3 * ((n - 1) ** 2)) / ((n - 2) * (n - 3)))
```

### 3-3. ì™œë„ì™€ ì²¨ë„ì˜ í™œìš©

ì™œë„ ë° ì²¨ë„ëŠ” ì•ì„œ ë§í–ˆë“  ìë£Œ ë¶„í¬ì˜ í˜•íƒœë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì¸¡ë„ë¡œ, ì‹¬í•œ ì™œë„ë¥¼ ê°€ì§€ê±°ë‚˜ í° ì²¨ë„ë¥¼ ê°€ì§€ëŠ” ê²½ìš° ìë£Œì— ì´ìƒì ì´ ìˆì„ ê°€ëŠ¥ì„±ì´ ë†’ë‹¤.  

ìë£Œì˜ ë¶„í¬ê°€ ì •ê·œ ë¶„í¬ë¥¼ ë”°ë¥´ëŠ”ì§€ í™•ì¸í•˜ëŠ” ê²ƒì„ **ì •ê·œì„± ê²€ì •(Normality Test)**ì´ë¼ê³  í•˜ëŠ”ë°, ì™œë„ ë° ì²¨ë„ë¥¼ í†µí•´ ê²€ì •í•˜ëŠ” ëŒ€í‘œì ì¸ ë°©ë²•ì´ Jarque-Bera ê²€ì •ìœ¼ë¡œ ì•„ë˜ì™€ ê°™ì´ ê³„ì‚°í•œë‹¤.  

$$JB = \frac{n}{6} \left\{ b_{1} + \frac{(b_{2} - 3)^{2}}{4} \right\}$$

ìœ„ ê³µì‹ì„ Pythonìœ¼ë¡œ êµ¬í˜„í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.  

```python
numeric = list[int | float]


def jarque_bera(data: numeric, dof: int = 0) -> float:
    """returns Jarque-Bera normality test value"""

    return (len(data) / 6) * (skew(data, dof) ** 2 + ((kurtosis_norm(data, dof) ** 2) / 4))
```

ì•„ë˜ì™€ ê°™ì´ SciPyë¥¼ ì´ìš©í•´ì„œ Jarque-Bera ê²€ì • ê²°ê³¼ë¥¼ ì‰½ê²Œ êµ¬í•  ìˆ˜ ìˆë‹¤.  

```python
import numpy as np
from scipy.stats import jarque_bera

data = np.random.default_rng(seed=0).normal(0, 1, 3000)

print(jarque_bera(data))
```

---
## Reference
- [êµ¬í˜„í•œ í•¨ìˆ˜ git repository](https://github.com/djccnt15/mathematics)