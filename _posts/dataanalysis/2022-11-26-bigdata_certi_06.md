---
published: true
layout: post
title: '[ë¹…ë¶„ê¸°] ì‹¤ê¸° ëŒ€ë¹„ 06'
description: >
    ë¹…ë°ì´í„° ë¶„ì„ê¸°ì‚¬ ì‹¤ê¸° ê¸°ì¶œ ì‘ì—…í˜• ë¬¸ì œ 4íšŒì°¨ í’€ì´
categories: [DataAnalysis]
tags: [data analysis, Bigdata Certificate]
image:
    path: /assets/img/posts/bigdata_certi.png
related_posts:
    - _posts/dataanalysis/2022-11-10-bigdata_certi_05.md
---
* toc
{:toc}

{% include series_bigdatacerti.html %}

## ê°œìš”

ë¹…ë°ì´í„° ë¶„ì„ê¸°ì‚¬ ì‹¤ê¸° ì¤€ë¹„ë¥¼ ìœ„í•œ 4íšŒì°¨ ì‹œí—˜ ì‘ì—…í˜• ê¸°ì¶œ ë¬¸ì œ ë‹µ ì •ë¦¬. [í‡´ê·¼í›„ë”´ì§“](https://www.youtube.com/@ai-study)ë‹˜ì˜ ë³µì›ì„ ì°¸ê³ í•¨([ì¶œì²˜](https://www.kaggle.com/datasets/agileteam/bigdatacertificationkr))  

## ì‘ì—…í˜• 1ìœ í˜•

### ë¬¸ì œ 1-1

age ì»¬ëŸ¼ì˜ 3ì‚¬ë¶„ìœ„ìˆ˜ì™€ 1ì‚¬ë¶„ìœ„ìˆ˜ì˜ ì°¨ë¥¼ ì ˆëŒ€ê°’ìœ¼ë¡œ êµ¬í•˜ê³ , ì†Œìˆ˜ì  ë²„ë ¤ì„œ, ì •ìˆ˜ë¡œ ì¶œë ¥  

```python
import pandas as pd

df = pd.read_csv('data/4th/basic1.csv')
res = int(abs(df['age'].quantile(0.75) - df['age'].quantile(0.25)))

print(res)
```
```
50
```

### ë¬¸ì œ 1-2

(loves ë°˜ì‘ + wows ë°˜ì‘) / (reactions ë°˜ì‘) ë¹„ìœ¨ì´ 0.4ë³´ë‹¤ í¬ê³  0.5ë³´ë‹¤ ì‘ìœ¼ë©´ì„œ, status_typeì´ 'video'ì¸ ë°ì´í„°ì˜ ê°œìˆ˜  

```python
import pandas as pd

df = pd.read_csv('data/4th/fb.csv')
ratio = (df['loves'] + df['wows']) / df['reactions']
cond_1 = ratio > 0.4
cond_2 = ratio < 0.5
cond_3 = df['type'] == 'video'
res = len(df.loc[cond_1 & cond_2 & cond_3])

print(res)
```
```
90
```

### ë¬¸ì œ 1-3

date_addedê°€ 2018ë…„ 1ì›” ì´ë©´ì„œ countryê°€ United Kingdom ë‹¨ë… ì œì‘ì¸ ë°ì´í„°ì˜ ê°œìˆ˜  

```python
import pandas as pd

df = pd.read_csv('data/4th/nf.csv')
df['date_added'] = pd.to_datetime(df['date_added'])
cond_1 = df['country'] == "United Kingdom"
cond_2 = df['date_added'].dt.year == 2018
cond_3 = df['date_added'].dt.month == 1
res = len(df.loc[cond_1 & cond_2 & cond_3])

print(res)
```
```
6
```

## ì‘ì—…í˜• 2ìœ í˜•

ê¸°ì¡´ ê³ ê° ë¶„ë¥˜ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹ ê·œ ê³ ê°ì´ ì–´ë–¤ ë¶„ë¥˜ì— ì†í• ì§€ ì˜ˆì¸¡  

- ì˜ˆì¸¡í•  ê°’(y): "Segmentation" (1,2,3,4)

**ì œì¶œ í˜•ì‹**

```
ID,Segmentation
458989,1
458994,2
459000,3
459003,4
```

### í’€ì´

**ë°ì´í„° ì½ê¸°**

```python
import pandas as pd

train = pd.read_csv('data/4th/train.csv')
test = pd.read_csv('data/4th/test.csv')
```

**EDA**

```python
print(train.info())
```

<details><summary>terminal</summary><div markdown="1">
```
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 6665 entries, 0 to 6664
Data columns (total 11 columns):
 #   Column           Non-Null Count  Dtype  
---  ------           --------------  -----  
 0   ID               6665 non-null   int64  
 1   Gender           6665 non-null   object 
 2   Ever_Married     6665 non-null   object 
 3   Age              6665 non-null   int64  
 4   Graduated        6665 non-null   object 
 5   Profession       6665 non-null   object 
 6   Work_Experience  6665 non-null   float64
 7   Spending_Score   6665 non-null   object 
 8   Family_Size      6665 non-null   float64
 9   Var_1            6665 non-null   object 
 10  Segmentation     6665 non-null   int64  
dtypes: float64(2), int64(3), object(6)
memory usage: 572.9+ KB
None
```
</div></details><br>

```python
print(test.info())
```

<details><summary>terminal</summary><div markdown="1">
```
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 2154 entries, 0 to 2153
Data columns (total 10 columns):
 #   Column           Non-Null Count  Dtype  
---  ------           --------------  -----  
 0   ID               2154 non-null   int64  
 1   Gender           2154 non-null   object 
 2   Ever_Married     2154 non-null   object 
 3   Age              2154 non-null   int64  
 4   Graduated        2154 non-null   object 
 5   Profession       2154 non-null   object 
 6   Work_Experience  2154 non-null   float64
 7   Spending_Score   2154 non-null   object 
 8   Family_Size      2154 non-null   float64
 9   Var_1            2154 non-null   object 
dtypes: float64(2), int64(2), object(6)
memory usage: 168.4+ KB
None
```
</div></details><br>

ë¬¸ì œì˜ ì¢…ë¥˜ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•´ target ì¹¼ëŸ¼ì¸ Segmentation ì¹¼ëŸ¼ì— ì¡´ì¬í•˜ëŠ” uniqueí•œ ë°ì´í„°ë¥¼ í™•ì¸í•˜ê³  multiple classficationì¸ ê²ƒì„ í™•ì¸í•œë‹¤.  

```python
print(train['Segmentation'].unique())
```
```
[4 2 3 1]
```

**í…Œì´ë¸” ë³‘í•©**

í•™ìŠµìš© ë°ì´í„°ì™€ ê²€ì¦ìš© ë°ì´í„°ë¥¼ í•©ì³ë²„ë¦¬ë©´ ì—¬ëŸ¬ ê°€ì§€ ì „ì²˜ë¦¬ë¥¼ í•œë²ˆì— ì²˜ë¦¬í•˜ëŠ” ê¼¼ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.  

```python
df = pd.concat([train, test])
```

ì „ì²˜ë¦¬ë¥¼ ìœ„í•´ ëª…ëª©ë³€ìˆ˜ì™€ ìˆ˜ì¹˜í˜•ë³€ìˆ˜ë¥¼ ë¶„ë¦¬í•´ì¤€ë‹¤.  

```python
cols_obj = df.select_dtypes(include='object').columns
cols_num = [col for col in df.columns if col not in cols_obj and col not in ['ID', 'Segmentation']]
```
```python
print(cols_obj)
```
```
Index(['Gender', 'Ever_Married', 'Graduated', 'Profession', 'Spending_Score', 'Var_1'], dtype='object')
```

ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë¥¼ í™•ì¸í•´ë³´ë©´, ëª…ëª©ë³€ìˆ˜ê°€ One-Hot Encodingì´ ë˜ì–´ ìˆëŠ” í˜•íƒœì´ê±°ë‚˜, ì •ê·œí™”ê°€ í¬ê²Œ í•„ìš”í•˜ì§€ëŠ” ì•Šì€ ë°ì´í„°ì¸ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.  

```python
print(cols_num)
```
```
['Age', 'Work_Experience', 'Family_Size']
```

test ë°ì´í„° ì…‹ì˜ `id` í•­ëª©ì€ ê²°ê³¼ ì œì¶œ ì‹œì— ì¬í™œìš©í•´ì•¼í•˜ë‹ˆ ë”°ë¡œ ì €ì¥í•´ë‘”ë‹¤.  

```python
id = test.iloc[:, 0]
```

**Label Encoding**

ë²”ì£¼ê°€ ë‘ ê°œë§Œ ìˆê±°ë‚˜ ì„œì—´í˜• ë³€ìˆ˜ë¡œ ì·¨ê¸‰í• ë§Œí•œ í•­ëª©ë“¤ì€ Label Encodingìœ¼ë¡œ ë³€í™˜í•´ì£¼ëŠ”ê²Œ ì¢‹ë‹¤.  

```python
[print(f'{col}={df[col].unique()}') for col in cols_obj]
```
```
Gender=['Male' 'Female']
Ever_Married=['No' 'Yes']
Graduated=['No' 'Yes']
Profession=['Healthcare' 'Engineer' 'Lawyer' 'Artist' 'Doctor' 'Homemaker' 'Entertainment' 'Marketing' 'Executive']
Spending_Score=['Low' 'High' 'Average']
Var_1=['Cat_4' 'Cat_6' 'Cat_7' 'Cat_3' 'Cat_1' 'Cat_2' 'Cat_5']
```

ë°˜ë³µë¬¸ìœ¼ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ë²”ì£¼ê°€ ë‘ ê°œì¸ ì¹¼ëŸ¼ë“¤ì˜ ëª©ë¡ì„ ë§Œë“¤ê³ , ì„œì—´í˜•ìœ¼ë¡œ ì·¨ê¸‰í•  ë³€ìˆ˜ì˜ ìˆœì„œë¥¼ ë§Œë“¤ì–´ì¤€ë‹¤.  

```python
cols_binary = ['Gender', 'Ever_Married', 'Graduated']
col_spend = ['Low', 'Average', 'High']
col_var = ['Cat_1', 'Cat_2', 'Cat_3', 'Cat_4', 'Cat_5', 'Cat_6', 'Cat_7']
```

Label Encodingì„ ì§„í–‰í•´ì¤€ë‹¤. ë§Œì•½ ë°ì´í„°ì…‹ì„ í•©ì³ë‘ì§€ ì•Šì•˜ë‹¤ë©´ 'Spending_Score', 'Var_1' ì¹¼ëŸ¼ì— ì ìš©í•œ ê²ƒì²˜ëŸ¼ Label Encodingì„ ì ìš©í•  ê° ì¹¼ëŸ¼ ì „ìš©ì˜ encoderë¥¼ ì„ ì–¸í•´ì„œ fit ì •ë³´ë¥¼ ì €ì¥í•´ì¤˜ì•¼ ì¬í™œìš©í•  ìˆ˜ ìˆë‹¤.  

```python
from sklearn.preprocessing import LabelEncoder

encoder = LabelEncoder()
for col in cols_binary:
    df[col] = encoder.fit_transform(df[col])

encoder_spend = LabelEncoder()
encoder_spend.fit(col_spend)
df['Spending_Score'] = encoder_spend.transform(df['Spending_Score'])

encoder_var = LabelEncoder()
encoder_var.fit(col_var)
df['Var_1'] = encoder_var.transform(df['Var_1'])
```

**One-Hot Encoding**

ë‚¨ì€ ë²”ì£¼í˜• ë³€ìˆ˜ ì¹¼ëŸ¼ì— ëŒ€í•œ One-Hot Encodingì„ ì§„í–‰í•œë‹¤. ìœ„ì—ì„œ label encodingì„ ì§„í–‰í•˜ì—¬ í˜„ì¬ ìƒíƒœì—ì„œëŠ” ëª¨ë“  object íƒ€ì… ì¹¼ëŸ¼ì„ ëŒ€ìƒìœ¼ë¡œ one-hot encodingì„ í•´ì£¼ë©´ ë˜ê¸° ë•Œë¬¸ì— `columns` íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì•„ë„ ë˜ì§€ë§Œ ì—°ìŠµ ê²¸ ì ìš©í•´ë³¸ë‹¤. `columns` íŒŒë¼ë¯¸í„°ì— ì¸ìë¥¼ ì…ë ¥í•´ì£¼ë©´ í•´ë‹¹ ì¹¼ëŸ¼ë“¤ì— ëŒ€í•´ì„œë§Œ One-Hot Encodingì„ ì§„í–‰í•œë‹¤.  

```python
df = pd.get_dummies(data=df, columns=['Profession'])

print(df.info())
```

<details><summary>terminal</summary><div markdown="1">
```
<class 'pandas.core.frame.DataFrame'>
Int64Index: 8819 entries, 0 to 2153
Data columns (total 19 columns):
 #   Column                    Non-Null Count  Dtype  
---  ------                    --------------  -----  
 0   ID                        8819 non-null   int64  
 1   Gender                    8819 non-null   int32  
 2   Ever_Married              8819 non-null   int32  
 3   Age                       8819 non-null   int64  
 4   Graduated                 8819 non-null   int32  
 5   Work_Experience           8819 non-null   float64
 6   Spending_Score            8819 non-null   int32  
 7   Family_Size               8819 non-null   float64
 8   Var_1                     8819 non-null   int32  
 9   Segmentation              6665 non-null   float64
 10  Profession_Artist         8819 non-null   uint8  
 11  Profession_Doctor         8819 non-null   uint8  
 12  Profession_Engineer       8819 non-null   uint8  
 13  Profession_Entertainment  8819 non-null   uint8  
 14  Profession_Executive      8819 non-null   uint8  
 15  Profession_Healthcare     8819 non-null   uint8  
 16  Profession_Homemaker      8819 non-null   uint8  
 17  Profession_Lawyer         8819 non-null   uint8  
 18  Profession_Marketing      8819 non-null   uint8  
dtypes: float64(3), int32(5), int64(2), uint8(9)
memory usage: 663.1 KB
None
```
</div></details><br>

**í…Œì´ë¸” ë¶„ë¦¬**

ì „ì²˜ë¦¬ë¥¼ ì‰½ê²Œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ í•©ì³ë‘ì—ˆë˜ train set ë°ì´í„°ì™€ test set ë°ì´í„°ë¥¼ ë‹¤ì‹œ ë¶„ë¦¬í•˜ê³ , ëª¨ë¸ë¡œ test set ë°ì´í„°ë¥¼ inferenceí•˜ëŠ”ë° ë¶ˆí•„ìš”í•œ ì¹¼ëŸ¼ì„ ì œê±°í•´ì¤€ë‹¤.  

```python
train = df.iloc[:train.shape[0]]
test = df.iloc[train.shape[0]:]

test.drop(columns=['Segmentation', 'ID'], inplace=True)
```

**ë…ë¦½ë³€ìˆ˜/ì¢…ì†ë³€ìˆ˜ ë¶„ë¦¬**

ëª¨ë¸ì˜ í•™ìŠµì„ ìœ„í•´ ë…ë¦½ë³€ìˆ˜ì™€ ì¢…ì†ë³€ìˆ˜ë¥¼ ë¶„ë¦¬í•´ì¤€ë‹¤.  

```python
import numpy as np

endog = np.array(train['Segmentation']).reshape(-1, 1)
exog = train.drop(columns=['Segmentation', 'ID'])
```

**ëª¨ë¸ ìƒì„±/í•™ìŠµ/í‰ê°€**

ë‹¤ì¤‘ ë¶„ë¥˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë¬¸ì œì´ë¯€ë¡œ, KNN ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ê¸°ë¡œ í•œë‹¤. ì¢…ì†ë³€ìˆ˜ëŠ” ì‚¬ì‹¤ ê·¸ëŒ€ë¡œ ë„£ì–´ë„ ìë™ìœ¼ë¡œ ì ìš© ë˜ëŠ”ë°, scikit-learnì—ì„œ `(1, -1)` í˜•íƒœë¡œ ë°”ê¿”ë‹¬ë¼ëŠ” ê²½ê³ ê°€ ë– ì„œ `flatten` í•¨ìˆ˜ë¥¼ í†µí•´ 1ì°¨ì›ìœ¼ë¡œ ë³€í™˜ì‹œì¼œì¤¬ë‹¤.  

ê·¸ë¦¬ê³  ëª¨ë¸ì˜ êµì°¨ ê²€ì¦(cross validation)ì„ ìœ„í•´ `cross_val_score` APIë¥¼ ì‚¬ìš©í–ˆëŠ”ë°, [ê³µì‹ ë¬¸ì„œ](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)ë¥¼ ë³´ë©´ `cv` ì˜µì…˜ì´ ì •ìˆ˜ì¼ ê²½ìš° ìë™ìœ¼ë¡œ `StratifiedKFold`ë¥¼ ì ìš©í•´ì¤€ë‹¤ê³  í•œë‹¤.  

KNN ì•Œê³ ë¦¬ì¦˜ì€ ì˜ˆì¸¡í•  ë°ì´í„°ì˜ ìœ„ì¹˜ ì£¼ë³€ì˜ ë‹¤ë¥¸ ë°ì´í„°ë“¤ì„ í†µí•´ ì–´ëŠ ì§‘ë‹¨ì— ì†í• ì§€ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì¸ë°, `n_neighbors`ëŠ” ê°€ì¥ ê°€ê¹Œìš´ ëª‡ ê°œì˜ ë°ì´í„°ë¥¼ ë³¼ ì§€ ê²°ì •í•˜ëŠ” ì˜µì…˜ì´ë‹¤. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ ìœ„í•´ `n_neighbors`ì˜ ê°’ì„ ì ì ˆíˆ ë³€í™”ë¥¼ ì£¼ë©´ì„œ í™•ì¸í•´ë³¸ë‹¤.  

```python
from sklearn.model_selection import cross_val_score
from sklearn.neighbors import KNeighborsClassifier as KNN

endog = endog.flatten()

score = [{'i': i, 'score_mean': cross_val_score(KNN(n_neighbors=i), X=exog, y=endog, cv=5).mean()} for i in range(10, 500, 10)]
score = pd.DataFrame(score).sort_values(by='score_mean', ascending=False)

print(score.head())
```
```
    i  score_mean
2  30    0.480870
1  20    0.476669
3  40    0.474119
5  60    0.471118
4  50    0.470818
```

ğŸ’¡ `cross_val_score` APIëŠ” `scoring` íŒŒë¼ë¯¸í„°ë¥¼ ì…ë ¥í•˜ì§€ ì•Šìœ¼ë©´ ë¶„ë¥˜ ë¬¸ì œì¼ ê²½ìš° ê¸°ë³¸ê°’ìœ¼ë¡œ accuracyë¥¼ ì‚¬ìš©í•œë‹¤ê³  í•œë‹¤.  
{:.note}

ê²°ê³¼ì¹˜ê°€ í° ì°¨ì´ê°€ ìˆì§€ëŠ” ì•Šì§€ë§Œ, ì–´ì¨Œë“  ê°€ì¥ í‰ê·  ì ìˆ˜ê°€ ë†’ê²Œ ë‚˜ì˜¨ `n_neighbors` ê°’ìœ¼ë¡œ ëª¨ë¸ì„ í•™ìŠµì‹œì¼œì¤€ë‹¤.  

```python
model = KNN(n_neighbors=score.iloc[0, 0])
model.fit(X=exog, y=endog)

print(model.classes_)
```
```
[1. 2. 3. 4.]
```

**í•™ìŠµëœ ëª¨ë¸ì„ í™œìš©í•œ í™•ë¥  ì˜ˆì¸¡**

ë¬¸ì œì—ì„œ ì–´ë–¤ ë¶„ë¥˜ì— ì†í• ì§€ë¥¼ ì˜ˆì¸¡í•˜ë¼ê³  í–ˆìœ¼ë¯€ë¡œ `predict` ë©”ì„œë“œë¥¼ ì´ìš©í•´ì„œ test set ë°ì´í„°ì— ì ìš©í•´ì¤€ë‹¤.  

```python
predict = model.predict(test)

print(predict)
```
```
[1. 3. 3. ... 2. 3. 3.]
```

ì°¸ê³ ë¡œ ê° ë¶„ë¥˜ì— ì†í•  í™•ë¥ ì„ ì˜ˆì¸¡í•˜ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ì™€ ê°™ì´ `predict_proba` ë©”ì„œë“œë¥¼ ì ìš©í•˜ë©´ ëœë‹¤.  

```python
predict_proba = model.predict_proba(test)

print(predict_proba)
```
```
[[0.36666667 0.3        0.13333333 0.2       ]
 [0.23333333 0.3        0.4        0.06666667]
 [0.1        0.36666667 0.53333333 0.        ]
 ...
 [0.26666667 0.43333333 0.06666667 0.23333333]
 [0.16666667 0.33333333 0.43333333 0.06666667]
 [0.26666667 0.2        0.3        0.23333333]]
```

ì €ì¥í•´ë‘” `id`ì™€ ì¶œë ¥ëœ `predict`ì˜ ê°œìˆ˜ê°€ ì²˜ìŒ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¨ test set ë°ì´í„°ì˜ ê°œìˆ˜ì™€ ë™ì¼í•œ ê²ƒì„ í™•ì¸í•´ì¤€ë‹¤.  

```python
print(len(id), len(predict))
```
```
2154 2154
```

**ê²°ê³¼ ë°ì´í„° ìƒì„±**

`id`ì™€ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì´ìš©í•´ì„œ ì œì¶œìš© ê²°ê³¼ë¥¼ ë§Œë“¤ê³ , ì •ìƒì ìœ¼ë¡œ ë§Œë“¤ì—ˆëŠ”ì§€ í™•ì¸í•´ì¤€ë‹¤. ì œì¶œ ì˜ˆì‹œì— ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì •ìˆ˜í˜• ìë£Œë¡œ ì œì¶œí•˜ë„ë¡ ì œì‹œë˜ì—ˆê¸° ë•Œë¬¸ì— ì‹¤ìˆ˜í˜• ë°ì´í„°ë¡œ ì €ì¥ëœ ê²°ê³¼ë¥¼ ì •ìˆ˜í˜•ìœ¼ë¡œ ë°”ê¿”ì£¼ì–´ì•¼ í•œë‹¤.  

```python
result = pd.DataFrame({'ID': id, 'Segmentation': predict})
result['Segmentation'] = result['Segmentation'].astype(int)

print(result.head())
```
```
       ID  Segmentation
0  458989             1
1  458994             3
2  459000             3
3  459003             2
4  459005             2
```

**ì œì¶œìš© íŒŒì¼ ì €ì¥**

ë‹µì•ˆ ì œì¶œìš© íŒŒì¼ì„ ì €ì¥í•´ì¤€ë‹¤. ì œì‹œëœ ì œì¶œ ê²°ê³¼ì™€ ë™ì¼í•œ ì–‘ì‹ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ì–´ì•¼ í•œë‹¤.  

```python
result.to_csv('result.csv', index=False)
```

### í†µí•© ì½”ë“œ ë° ì£¼ì„

```python
import numpy as np
import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import cross_val_score
from sklearn.neighbors import KNeighborsClassifier as KNN

# data load
train = pd.read_csv('data/4th/train.csv')
test = pd.read_csv('data/4th/test.csv')

# EDA
print(train.info())
print(test.info())
print(train['Segmentation'].unique())

# table concat for preprocessing
df = pd.concat([train, test])

cols_obj = df.select_dtypes(include='object').columns
cols_num = [col for col in df.columns if col not in cols_obj and col not in ['ID', 'Segmentation']]

print(cols_obj)
print(cols_num)

# save id of test set data
id = test.iloc[:, 0]

# label encoding
[print(f'{col}={df[col].unique()}') for col in cols_obj]

cols_binary = ['Gender', 'Ever_Married', 'Graduated']
col_spend = ['Low', 'Average', 'High']
col_var = ['Cat_1', 'Cat_2', 'Cat_3', 'Cat_4', 'Cat_5', 'Cat_6', 'Cat_7']

encoder = LabelEncoder()
for col in cols_binary:
    df[col] = encoder.fit_transform(df[col])

encoder_spend = LabelEncoder()
encoder_spend.fit(col_spend)
df['Spending_Score'] = encoder_spend.transform(df['Spending_Score'])

encoder_var = LabelEncoder()
encoder_var.fit(col_var)
df['Var_1'] = encoder_var.transform(df['Var_1'])

# one-hot encoding
df = pd.get_dummies(df)

# train/test split
train = df.iloc[:train.shape[0]]
test = df.iloc[train.shape[0]:]

test.drop(columns=['Segmentation', 'ID'], inplace=True)

# separate dependent/independent variable from train set
endog = np.array(train['Segmentation']).reshape(-1, 1)
exog = train.drop(columns=['Segmentation', 'ID'])

# calculate cross validation score for hyperparameter tuning
endog = endog.flatten()

score = [{'i': i, 'score_mean': cross_val_score(KNN(n_neighbors=i), X=exog, y=endog, cv=5).mean()} for i in range(10, 500, 10)]
score = pd.DataFrame(score).sort_values(by='score_mean', ascending=False)
print(score.head())

# load model and fit model
model = KNN(n_neighbors=score.iloc[0, 0])
model.fit(X=exog, y=endog)

print(model.classes_)

# inference test set with fitted model
predict = model.predict(test)

print(predict)

# make result table to make csv file
result = pd.DataFrame({'ID': id, 'Segmentation': predict})
result['Segmentation'] = result['Segmentation'].astype(int)

print(result.head())

# save csv file
result.to_csv('result.csv', index=False)
```

---
## Reference
- [ì£¼í”¼í„° ë…¸íŠ¸ë¶](https://github.com/djccnt15/bigdata_certi/blob/main/example_04.ipynb)
- [4th-type1-python](https://www.kaggle.com/code/agileteam/4th-type1-python/notebook)
- [4th-t2-python](https://www.kaggle.com/code/agileteam/4th-t2-python/notebook)
- [Big Data Analytics Certification KR 2022](https://www.kaggle.com/competitions/big-data-analytics-certification-kr-2022/data)